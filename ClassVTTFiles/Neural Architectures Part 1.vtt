WEBVTT - This file was automatically generated by VIMEO

0
00:00:08.185 --> 00:00:09.125
Uh, hey everyone.

1
00:00:09.345 --> 00:00:11.525
Um, this is, um, Navin.

2
00:00:11.825 --> 00:00:13.085
Uh, uh, I'm here

3
00:00:13.105 --> 00:00:15.445
to teach you the new architectures class today.

4
00:00:17.025 --> 00:00:20.365
Uh, quick, uh, brief overview about me.

5
00:00:20.465 --> 00:00:22.525
Um, I want to quickly introduce myself.

6
00:00:23.385 --> 00:00:28.065
Uh, I currently work as VP

7
00:00:28.065 --> 00:00:29.665
of AI and Engineering at Vouch.

8
00:00:30.125 --> 00:00:33.985
Uh, prior to that, I led teams at Amazon Private Brands

9
00:00:33.985 --> 00:00:36.105
Discovery, uh, for their applied science

10
00:00:36.165 --> 00:00:39.985
and engineering teams, uh, to deliver recommendations.

11
00:00:41.305 --> 00:00:44.385
I live in Seattle. I have a master's, uh,

12
00:00:44.525 --> 00:00:46.345
in computer science from Gers.

13
00:00:47.355 --> 00:00:51.495
And, um, most of my experience over the years is in NLP

14
00:00:52.175 --> 00:00:53.975
Computer Vision, uh, spaces.

15
00:00:55.035 --> 00:01:00.015
Um, so overall, 17, 17 years, uh, in, in various roles, uh,

16
00:01:00.075 --> 00:01:01.255
across these companies.

17
00:01:02.035 --> 00:01:04.255
Um, so that's a little bit about me.

18
00:01:04.975 --> 00:01:09.275
Uh, if you have a moment, uh, please pop in your,

19
00:01:10.215 --> 00:01:13.755
uh, name, um, your role, your company,

20
00:01:14.215 --> 00:01:17.395
or, uh, where you're working at, uh,

21
00:01:17.415 --> 00:01:19.955
and where you're based, just to get an, get a sense of,

22
00:01:19.955 --> 00:01:22.915
you know, uh, I want to know, uh, who my, uh,

23
00:01:23.675 --> 00:01:24.875
students are for today.

24
00:01:25.455 --> 00:01:28.555
So, uh, so take a moment to do that, uh,

25
00:01:28.555 --> 00:01:30.635
and post that in your chat windows.

26
00:01:33.775 --> 00:01:35.515
I'm nice to meet you.

27
00:01:46.715 --> 00:01:51.535
Morado ran awesome,

28
00:01:53.175 --> 00:01:56.155
uh, messaging IK team real quick.

29
00:01:56.655 --> 00:02:00.235
So, alright, let's keep moving.

30
00:02:01.675 --> 00:02:01.895
Um,

31
00:02:08.735 --> 00:02:11.195
so overall, um, um,

32
00:02:11.755 --> 00:02:13.755
I think you guys have been going

33
00:02:13.755 --> 00:02:14.875
through several different classes.

34
00:02:15.135 --> 00:02:19.235
So, neural architectures is, um, this is a class today,

35
00:02:19.255 --> 00:02:20.315
the ML 17 class.

36
00:02:20.455 --> 00:02:23.355
So today we'll learn about, um, various aspects

37
00:02:23.355 --> 00:02:26.195
of neural architecture, the Feedforward neural networks,

38
00:02:27.145 --> 00:02:28.235
CNNs and RNs.

39
00:02:28.535 --> 00:02:30.795
Uh, so we split the class into two sessions.

40
00:02:31.455 --> 00:02:34.315
Uh, so first day is, is about fns,

41
00:02:34.895 --> 00:02:38.755
and the next, uh, session is about, uh, CNNs

42
00:02:38.755 --> 00:02:40.795
and R Ns, just to give you a high level context.

43
00:02:46.485 --> 00:02:50.025
So, uh, yeah, so today we'll discuss about,

44
00:02:50.525 --> 00:02:52.185
um, uh, f and n.

45
00:02:52.285 --> 00:02:55.985
Uh, before that we'll do a quick review of, um, uh,

46
00:02:55.985 --> 00:02:59.125
various concepts you learned about neural networks, uh,

47
00:02:59.125 --> 00:03:00.605
and also intro to deep learning.

48
00:03:04.665 --> 00:03:07.845
And, um, um,

49
00:03:08.385 --> 00:03:12.405
and then we'll, we'll also go through a coding practice, um,

50
00:03:12.825 --> 00:03:14.565
for Feedforward neural networks.

51
00:03:15.185 --> 00:03:17.285
Uh, we'll have a short time for q and a,

52
00:03:17.285 --> 00:03:22.165
but, um, as, as you experienced in previous classes, uh,

53
00:03:22.425 --> 00:03:24.645
you can just ask questions during the class.

54
00:03:25.425 --> 00:03:27.645
Uh, just type it in the q and a section.

55
00:03:29.155 --> 00:03:30.455
If I ask questions

56
00:03:30.595 --> 00:03:33.255
and I'm requesting some participation,

57
00:03:33.325 --> 00:03:34.775
just type it in the chat window.

58
00:03:34.875 --> 00:03:36.095
So, so there is a distinction.

59
00:03:36.095 --> 00:03:39.775
So if you have question, type it in the q and a, either me

60
00:03:39.875 --> 00:03:43.455
or the TA present can answer those questions.

61
00:03:44.685 --> 00:03:49.095
I'll look at it, uh, in, in short time intervals.

62
00:03:49.315 --> 00:03:51.815
And I'll, I'll answer those questions, either live

63
00:03:51.875 --> 00:03:54.415
or through the chat, uh, feature.

64
00:03:55.075 --> 00:03:57.775
Uh, but if I ask questions for your participation,

65
00:03:57.775 --> 00:04:00.055
just type it in the webinar chat, just like you did.

66
00:04:02.945 --> 00:04:05.525
And, um, so that's the agenda for today.

67
00:04:06.065 --> 00:04:09.445
Uh, and, uh, if, if possible, I want to cover a little bit

68
00:04:09.445 --> 00:04:13.325
of CNNs today as well, uh, depending on how the, uh,

69
00:04:14.225 --> 00:04:17.765
uh, how much time we have left, um, that will give you, uh,

70
00:04:17.835 --> 00:04:20.445
give us more time for the next session so

71
00:04:20.445 --> 00:04:23.485
that we can spend more time on the second part of CNN's and,

72
00:04:23.585 --> 00:04:25.405
and instead of rushing them through.

73
00:04:26.025 --> 00:04:28.645
Um, so that's, uh, that's a brief agenda for today.

74
00:04:28.665 --> 00:04:31.485
Any questions on that before, uh, moving on?

75
00:04:33.745 --> 00:04:36.295
Awesome. Um, cool.

76
00:04:36.595 --> 00:04:41.055
I'm still working with the operations to help me become, uh,

77
00:04:41.245 --> 00:04:44.255
turn on my video, so just waiting on that.

78
00:04:44.955 --> 00:04:46.215
Uh, but we can keep moving.

79
00:04:49.025 --> 00:04:53.955
So, high level, um, want to get a sense like,

80
00:04:53.955 --> 00:04:58.115
you know, uh, from, from you guys, like, uh, like, uh,

81
00:04:58.745 --> 00:05:01.435
what are some techniques do you think that are involved in,

82
00:05:01.695 --> 00:05:05.155
you know, how YouTube generates subtitles for videos

83
00:05:05.535 --> 00:05:08.635
or, you know, when you unlock your iPhone, uh,

84
00:05:08.635 --> 00:05:10.915
using your face id, what's happening in the background?

85
00:05:11.375 --> 00:05:13.675
Um, just, just at a high level, like, you know, uh,

86
00:05:13.735 --> 00:05:15.075
no need of technical details.

87
00:05:15.075 --> 00:05:18.395
Like, what's, what's going on there, you know?

88
00:05:24.285 --> 00:05:28.385
All right. Uh, looks like my video is on. Um, cool.

89
00:05:29.345 --> 00:05:31.355
Back in business. Alright,

90
00:05:37.615 --> 00:05:39.345
good, good, good thinking there.

91
00:05:39.565 --> 00:05:41.705
So, think of inputs and outputs.

92
00:05:41.705 --> 00:05:43.825
So what is the input in each of these

93
00:05:43.925 --> 00:05:45.425
and what is output happening?

94
00:05:45.835 --> 00:05:47.385
Think of, think in those lines.

95
00:05:47.415 --> 00:05:49.785
That will give you some ideas, like what's going on there.

96
00:05:51.705 --> 00:05:55.205
So if you take the YouTube, right, so you are

97
00:05:55.905 --> 00:05:59.505
taking the, the video stream as input

98
00:06:00.045 --> 00:06:02.785
and generating text stream as output.

99
00:06:02.925 --> 00:06:06.825
So it's a, it's a conversion from one mod, one modality

100
00:06:06.885 --> 00:06:08.785
to another, but it's also a sequence.

101
00:06:08.885 --> 00:06:10.585
So it's a sequence to sequence problem.

102
00:06:11.755 --> 00:06:16.055
Um, it's a more advanced, um, uh,

103
00:06:16.415 --> 00:06:17.775
RNN type of problem.

104
00:06:18.155 --> 00:06:21.415
Um, sequence to sequence modeling, uh, which you learn,

105
00:06:21.455 --> 00:06:26.015
I think in the later stages of, um, NLP uh, co classes.

106
00:06:26.715 --> 00:06:29.855
Uh, but that's, that's what essentially is happening, uh,

107
00:06:29.915 --> 00:06:32.215
in the background, uh, for iPhone.

108
00:06:32.515 --> 00:06:34.775
Um, again, if you look at inputs

109
00:06:34.775 --> 00:06:36.655
and outputs, your face is the input

110
00:06:37.675 --> 00:06:41.815
and output is like a binary decision, yes or no.

111
00:06:43.045 --> 00:06:45.265
So it's kind of an object detection

112
00:06:45.605 --> 00:06:47.025
and classification problem.

113
00:06:47.205 --> 00:06:48.745
So, so the output is binary,

114
00:06:48.965 --> 00:06:50.825
so it's always giving you a zero

115
00:06:50.885 --> 00:06:53.425
or one, uh, whether to unlock or not.

116
00:06:54.165 --> 00:06:55.985
So think of along those lines.

117
00:06:56.165 --> 00:06:58.145
Uh, same thing with translate is it's

118
00:06:58.145 --> 00:06:59.305
a sequence to sequence problem.

119
00:06:59.325 --> 00:07:01.665
You have a sequence of text in one language

120
00:07:02.445 --> 00:07:05.705
and a sequence of text as output in another language.

121
00:07:06.975 --> 00:07:09.595
So a lot of, uh, good answers there.

122
00:07:10.575 --> 00:07:15.445
Um, so, so the goal is to, you know,

123
00:07:15.445 --> 00:07:17.605
look at, you know, some concrete ways on

124
00:07:17.605 --> 00:07:21.845
how these can be done, uh, which is the, uh, the motivation

125
00:07:22.185 --> 00:07:23.325
and goal of this course.

126
00:07:28.025 --> 00:07:30.685
Any more examples you could think of, like, you know, uh,

127
00:07:31.015 --> 00:07:34.285
where you see like, deep learning being used, uh,

128
00:07:34.315 --> 00:07:36.525
just like in the previous cases that we saw

129
00:07:54.905 --> 00:07:55.515
detection.

130
00:07:55.785 --> 00:07:56.075
Okay.

131
00:08:01.475 --> 00:08:01.695
Um,

132
00:08:07.325 --> 00:08:10.785
Understanding recommendations.

133
00:08:10.885 --> 00:08:12.265
Recommendations. Sure.

134
00:08:12.445 --> 00:08:16.025
Uh, it's a popular use case, um, where you are, uh,

135
00:08:16.025 --> 00:08:17.505
you know, you might, everyone

136
00:08:17.525 --> 00:08:20.345
of you might have experienced recommendations in various

137
00:08:20.525 --> 00:08:23.145
facets of your life, like, like, uh, shopping on Amazon

138
00:08:23.205 --> 00:08:24.825
or other e-commerce websites.

139
00:08:25.565 --> 00:08:26.625
Uh, search, yes.

140
00:08:27.085 --> 00:08:30.895
Um, so recommendations is again, a similarity problem

141
00:08:31.355 --> 00:08:33.575
or, uh, ranking problem.

142
00:08:33.915 --> 00:08:38.815
So where you have, uh, given an input list of,

143
00:08:39.075 --> 00:08:42.415
uh, x and a user, what is the right list of, uh,

144
00:08:42.425 --> 00:08:45.975
right rank list of X that we need to show to the user?

145
00:08:46.835 --> 00:08:51.455
Um, search is again, again, given an input string

146
00:08:51.715 --> 00:08:54.055
and a list of documents

147
00:08:54.115 --> 00:08:58.205
or links, uh, what is the right ranked list of documents.

148
00:08:59.065 --> 00:09:01.605
Um, so these are all ranking problems.

149
00:09:02.425 --> 00:09:04.805
Um, fake videos, I think, um,

150
00:09:06.645 --> 00:09:11.145
could be like, you know, um, an objection problem

151
00:09:11.395 --> 00:09:13.345
where you are looking for certain kind

152
00:09:13.345 --> 00:09:15.105
of artifacts in the image

153
00:09:15.205 --> 00:09:18.825
or video frames to see if this is real or fake.

154
00:09:19.765 --> 00:09:23.945
Um, yeah, all of good examples, right on the money there,

155
00:09:24.875 --> 00:09:29.345
Tesla, like lane recognition, autonomous driving, um,

156
00:09:31.275 --> 00:09:32.545
stock market predictions.

157
00:09:32.655 --> 00:09:34.345
Yeah. Yeah, absolutely.

158
00:09:36.105 --> 00:09:38.565
Uh, so all of these are good containers

159
00:09:38.625 --> 00:09:40.325
for deep learning problems for sure.

160
00:09:40.625 --> 00:09:44.805
Um, and we'll see why that's the case, uh, in a little bit.

161
00:09:57.075 --> 00:10:01.745
So just to quickly, uh, understand like, you know, uh,

162
00:10:02.055 --> 00:10:06.425
some quick fundamentals of neural networks, uh, we'll go

163
00:10:06.425 --> 00:10:08.385
through some of these topics, uh,

164
00:10:08.455 --> 00:10:11.105
that you might have already, um, learned.

165
00:10:11.165 --> 00:10:13.705
So let's look at what's in this particular section.

166
00:10:14.685 --> 00:10:17.665
So first, you know, we'll quickly introduce, you know,

167
00:10:17.665 --> 00:10:20.505
what deep learning is, uh, different ways

168
00:10:20.525 --> 00:10:24.875
to identify deep learning problems so far, you, you

169
00:10:25.485 --> 00:10:27.875
given based on your intuition, like, you know,

170
00:10:27.905 --> 00:10:29.035
what are some problems?

171
00:10:29.335 --> 00:10:32.755
Uh, but, um, uh, we'll try to understand, you know,

172
00:10:32.885 --> 00:10:35.635
based on characteristics of those problems.

173
00:10:35.705 --> 00:10:38.395
Like, you know, why this is a deep learning problem,

174
00:10:38.455 --> 00:10:42.275
what's this not, um, we'll look at, uh,

175
00:10:42.505 --> 00:10:44.915
deep learning versus, uh, new networks.

176
00:10:46.375 --> 00:10:49.115
And, um, and then also some real life

177
00:10:49.115 --> 00:10:50.395
applications of deep learning.

178
00:10:51.215 --> 00:10:55.675
Um, um, different advantages, challenges, uh,

179
00:10:55.725 --> 00:10:59.875
we'll also wrap it up by, uh, recap of loss functions,

180
00:11:00.655 --> 00:11:02.675
um, activation functions

181
00:11:02.675 --> 00:11:04.475
and gradient descent, uh, algorithm,

182
00:11:05.445 --> 00:11:08.075
which you might have already, uh, gone through.

183
00:11:09.465 --> 00:11:12.805
So that's a quick, uh, ou for this sections agenda

184
00:11:14.255 --> 00:11:16.715
before we move on to feed forward neural networks.

185
00:11:24.585 --> 00:11:29.095
Cool. So, so what is deep learning, um,

186
00:11:29.435 --> 00:11:30.655
in your experience?

187
00:11:30.765 --> 00:11:35.055
Like, you know, uh, um, if you want

188
00:11:35.055 --> 00:11:36.655
to take a shot at what deep learning

189
00:11:36.755 --> 00:11:38.255
is, what do you think it is?

190
00:11:48.075 --> 00:11:48.365
Cool.

191
00:11:54.195 --> 00:11:56.935
So it's essentially a branch of machine learning, uh,

192
00:11:57.155 --> 00:12:00.655
and, uh, it refers to architectures of neural networks

193
00:12:01.105 --> 00:12:04.855
where, uh, you know, which are composed of multiple layers,

194
00:12:05.555 --> 00:12:07.215
uh, of interconnected nodes.

195
00:12:07.215 --> 00:12:09.935
So, so, you know, uh, neural networks are kind of, you know,

196
00:12:10.215 --> 00:12:14.655
a generic term where you have, uh,

197
00:12:14.655 --> 00:12:16.815
different layers like, you know, input layer,

198
00:12:16.915 --> 00:12:19.015
hidden layer, and an output layer.

199
00:12:19.235 --> 00:12:21.455
But with deep learning, the, those number

200
00:12:21.455 --> 00:12:22.975
of hidden layers are huge.

201
00:12:23.595 --> 00:12:27.335
Um, and, um, so that's, that's why the term deep comes.

202
00:12:27.875 --> 00:12:30.335
Um, so it's essentially new network with lot

203
00:12:30.335 --> 00:12:32.615
of hidden layers, uh,

204
00:12:32.755 --> 00:12:36.375
and each layer receives input from previous layer, applies

205
00:12:37.135 --> 00:12:40.735
mathematical transformations, and produces their output.

206
00:12:40.795 --> 00:12:42.895
So that process keeps on repeating.

207
00:12:43.975 --> 00:12:47.955
Uh, in practice, a deep neural network can have, um,

208
00:12:48.915 --> 00:12:51.915
anywhere between dozen or, you know, even a hundred

209
00:12:52.415 --> 00:12:53.675
or even thousands of layers.

210
00:12:54.295 --> 00:12:58.845
Um, this, this sort of structure allows you to learn

211
00:12:59.525 --> 00:13:00.525
hierarchical representation.

212
00:13:00.825 --> 00:13:04.165
So, so each layer is learning from

213
00:13:04.165 --> 00:13:06.125
what the previous layers have already learned.

214
00:13:06.145 --> 00:13:08.845
So it's kind of building that hierarchy of learning.

215
00:13:09.625 --> 00:13:13.405
Uh, so that's why, um, the, the hierarchical

216
00:13:14.085 --> 00:13:16.045
learning comes from, uh, deep learning.

217
00:13:18.065 --> 00:13:21.325
Um, they're also capable of end-to-end learning.

218
00:13:21.745 --> 00:13:23.485
Uh, let me explain what that means.

219
00:13:24.625 --> 00:13:29.415
Um, so if you have built,

220
00:13:29.835 --> 00:13:33.215
uh, traditional classical ML models, um,

221
00:13:33.595 --> 00:13:36.935
you might have done like steps, like, you know, um, uh,

222
00:13:38.215 --> 00:13:40.455
transform the data, do some feature engineering

223
00:13:40.595 --> 00:13:42.655
and create features, um,

224
00:13:42.995 --> 00:13:45.775
and then apply the model, um,

225
00:13:46.155 --> 00:13:50.735
and, uh, evaluate and fine tune the model.

226
00:13:50.955 --> 00:13:55.055
So, deep learning is end-to-end in the sense that

227
00:13:55.955 --> 00:13:58.295
it doesn't involve creating features.

228
00:13:59.035 --> 00:14:01.095
You can create features and supply to it,

229
00:14:01.115 --> 00:14:05.175
but it's kind of t so deep learning is, is set up in a way

230
00:14:05.375 --> 00:14:09.995
that have to, you can rely on the network

231
00:14:10.295 --> 00:14:13.035
to learn the features as part of the model,

232
00:14:13.495 --> 00:14:14.515
uh, building process.

233
00:14:15.255 --> 00:14:16.835
Uh, so, so you don't have

234
00:14:16.835 --> 00:14:18.795
to hand create a lot of these features.

235
00:14:19.575 --> 00:14:22.155
And, uh, uh, the model itself learns

236
00:14:22.155 --> 00:14:23.275
them as part of the process.

237
00:14:23.365 --> 00:14:25.155
We'll look at it, uh, uh,

238
00:14:25.375 --> 00:14:27.235
in bit more detail in the next slides.

239
00:14:27.335 --> 00:14:32.155
But, um, um, that's one of the, the great, uh, aspects

240
00:14:32.215 --> 00:14:33.475
of, uh, deep learning.

241
00:14:35.575 --> 00:14:40.405
Um, as I said, each layer in deep neural network

242
00:14:40.965 --> 00:14:44.565
transforms input, um, uh, to a slightly more abstract,

243
00:14:45.305 --> 00:14:46.405
uh, representation.

244
00:14:47.225 --> 00:14:49.805
Uh, and for example, like if you take image,

245
00:14:49.935 --> 00:14:54.055
image recognition, uh, the first layer, um,

246
00:14:54.875 --> 00:14:58.135
let me see if I can use another slide, uh, for this.

247
00:14:59.795 --> 00:15:03.245
Okay. Um, so the first layer might identify like, you know,

248
00:15:03.245 --> 00:15:07.495
like an image recognition, um, might identify like, uh,

249
00:15:07.935 --> 00:15:09.655
abstract things like edges and stuff.

250
00:15:09.835 --> 00:15:12.695
Um, and the second layer init can,

251
00:15:13.675 --> 00:15:15.015
can learn from.

252
00:15:15.015 --> 00:15:17.535
These are just like small shapes, uh,

253
00:15:17.595 --> 00:15:20.295
and the next layer can learn bigger shapes

254
00:15:20.565 --> 00:15:21.735
from these small shapes.

255
00:15:21.735 --> 00:15:24.455
So, so that's the hierarchical learning I was referring to.

256
00:15:30.565 --> 00:15:32.305
And then in the final layer,

257
00:15:32.305 --> 00:15:35.265
you're making some logical conclusion about what,

258
00:15:35.375 --> 00:15:39.105
what the network has learned, like, you know, classify this

259
00:15:39.485 --> 00:15:44.065
as dog or cat or, or classify, uh, this as fraud

260
00:15:44.085 --> 00:15:48.305
or not, or, uh, in the face Id example, like, you know,

261
00:15:48.865 --> 00:15:51.585
classify this, whether it's it's the face that belongs

262
00:15:51.585 --> 00:15:54.025
to the person or not, things like that.

263
00:15:59.015 --> 00:16:01.875
So I told you how we'll look at how

264
00:16:01.875 --> 00:16:03.395
to identify deep planning problems.

265
00:16:03.575 --> 00:16:05.755
Uh, so these are some tenets.

266
00:16:06.455 --> 00:16:09.915
Um, so one is, you know, high dimensionality,

267
00:16:10.575 --> 00:16:11.635
uh, of data.

268
00:16:12.465 --> 00:16:15.435
Also, there is a lot of, um, uh, your data is very,

269
00:16:15.545 --> 00:16:16.875
very large dimensional.

270
00:16:18.465 --> 00:16:23.045
Um, uh, it's, uh, yeah, there could be unstructured data,

271
00:16:23.705 --> 00:16:28.365
uh, like, you know, images, uh, videos, uh,

272
00:16:28.715 --> 00:16:33.325
text, uh, um, um, you know, to begin with.

273
00:16:34.675 --> 00:16:36.375
Uh, it may not be tabular anymore.

274
00:16:37.195 --> 00:16:41.455
Um, and, um, you don't have a lot of domain knowledge.

275
00:16:41.715 --> 00:16:45.095
Uh, so, so like, you know, like, you know, uh, you don't,

276
00:16:45.515 --> 00:16:48.735
uh, have knowledge to do any feature engineering.

277
00:16:48.835 --> 00:16:50.135
So, so,

278
00:16:53.605 --> 00:16:55.945
so then you, you kind of require the model

279
00:16:55.965 --> 00:16:59.265
to automatically learn those, uh, patterns and features

280
00:16:59.685 --> 00:17:01.225
and representations from the data.

281
00:17:01.925 --> 00:17:04.985
Um, so, so these are some reasons

282
00:17:05.325 --> 00:17:10.025
or characteristics where, you know, um, you can, um, think

283
00:17:10.025 --> 00:17:12.265
of like, Hey, if you see a problem that kind

284
00:17:12.265 --> 00:17:14.265
of fits into this, these kind of buckets,

285
00:17:14.485 --> 00:17:15.665
that's a deep learning problem.

286
00:17:22.355 --> 00:17:25.815
Um, quick, quickly answering question from Rama.

287
00:17:25.875 --> 00:17:29.655
Um, FDL is a subset of ml y card ml take advantage of using.

288
00:17:30.095 --> 00:17:33.485
Absolutely. So, so this is how the, uh,

289
00:17:33.945 --> 00:17:35.565
the architectures have evolved, right?

290
00:17:35.665 --> 00:17:38.005
So, so in the, in the

291
00:17:38.795 --> 00:17:43.125
back in the day when deep learning is not popular, um,

292
00:17:45.065 --> 00:17:47.985
scientists and engineers really relied on doing a lot

293
00:17:47.985 --> 00:17:51.765
of feature engineering, uh, handcrafted feature engineering.

294
00:17:53.385 --> 00:17:57.485
And as deep learning evolved, uh, nowadays, um,

295
00:17:58.075 --> 00:18:00.645
even if you're using a non deep learning model

296
00:18:00.705 --> 00:18:04.285
for your modeling purpose, I've seen, uh, where, you know,

297
00:18:04.305 --> 00:18:06.885
you use, uh, auto encoders

298
00:18:06.985 --> 00:18:08.605
or other deep learning techniques

299
00:18:09.225 --> 00:18:10.725
to do the feature engineering

300
00:18:11.225 --> 00:18:15.165
and supply those features, uh, the layers as input

301
00:18:15.185 --> 00:18:16.445
to a ML model.

302
00:18:16.585 --> 00:18:20.405
So, so yes, it, uh, it is being taken advantage of.

303
00:18:20.585 --> 00:18:22.845
Uh, it's just how the things have evolved.

304
00:18:22.955 --> 00:18:26.525
Hope, hopefully that answers your question. Uh,

305
00:18:36.655 --> 00:18:36.945
cool.

306
00:18:37.245 --> 00:18:40.825
Um, so yes, so, uh,

307
00:18:41.615 --> 00:18:44.505
deep learning is a subset of, you know,

308
00:18:44.685 --> 00:18:48.905
how neur neur architectures, uh, neural networks are, uh,

309
00:18:49.485 --> 00:18:52.065
um, uh, architected.

310
00:18:52.565 --> 00:18:56.625
Um, so, so yes, it is, it is a subset of new networks.

311
00:19:12.155 --> 00:19:13.565
Alright, let's keep moving.

312
00:19:15.315 --> 00:19:19.475
Um, So again,

313
00:19:19.775 --> 00:19:24.235
as we, um, as deep learning was introduced,

314
00:19:24.615 --> 00:19:29.435
um, and become popular, um, what, what we've seen is,

315
00:19:30.175 --> 00:19:32.795
uh, deep planning is highly per performant.

316
00:19:33.175 --> 00:19:35.755
Um, so, uh, if you give,

317
00:19:35.865 --> 00:19:38.435
give deep planning models more data, um,

318
00:19:39.055 --> 00:19:40.355
it performs really well.

319
00:19:40.375 --> 00:19:44.035
So, so as you can see a representation in this graph, uh,

320
00:19:44.035 --> 00:19:47.795
like with the amount of data, um, the performance kind of,

321
00:19:47.895 --> 00:19:52.835
you know, scales linearly, um, very well, um, a lot

322
00:19:52.835 --> 00:19:57.035
of, you know, um, classical algorithms, um,

323
00:19:57.785 --> 00:20:00.315
sometimes, you know, with high dimensionality with,

324
00:20:00.345 --> 00:20:03.315
with more, uh, training data,

325
00:20:03.665 --> 00:20:05.155
they may not scale really well.

326
00:20:05.995 --> 00:20:09.135
And so, uh, so they have a plateau, uh,

327
00:20:09.135 --> 00:20:13.375
because it's, it's the capacity of the model to learn

328
00:20:14.055 --> 00:20:17.935
representations, uh, is plateaued for older algorithms

329
00:20:17.935 --> 00:20:19.055
or classical algorithms.

330
00:20:19.555 --> 00:20:23.615
Uh, deep learning excels in this, um, area, uh,

331
00:20:23.615 --> 00:20:25.415
because you can introduce a lot

332
00:20:25.415 --> 00:20:27.535
of complexity into the model, uh,

333
00:20:27.635 --> 00:20:29.495
by architecting it in the right way.

334
00:20:31.955 --> 00:20:33.495
It could be logistic regression

335
00:20:33.635 --> 00:20:34.975
or, you know, gradient boost,

336
00:20:35.155 --> 00:20:38.975
or, uh, it could be, uh, so I'm answering question for, um,

337
00:20:39.005 --> 00:20:41.655
what would be an example holder learning algorithm.

338
00:20:42.155 --> 00:20:45.415
Um, so you can put anything, uh, non deep learning there,

339
00:20:45.715 --> 00:20:50.485
um, SPMS or uh, HBUs and stuff like that.

340
00:20:59.405 --> 00:21:03.645
Alright, So this is something I

341
00:21:03.645 --> 00:21:04.725
was referring to earlier.

342
00:21:05.145 --> 00:21:10.125
Uh, so, uh, again, giving you a bit of intuition in how, uh,

343
00:21:10.385 --> 00:21:12.405
the hierarchical learning works.

344
00:21:13.185 --> 00:21:17.925
So, uh, so here is an face recognition problem applied,

345
00:21:18.465 --> 00:21:19.765
uh, using deep learning.

346
00:21:21.365 --> 00:21:26.145
And, um, here you can see in the layer one, the uc is kind

347
00:21:26.145 --> 00:21:28.705
of learning like all the, all the edges.

348
00:21:29.365 --> 00:21:30.425
Um, uh,

349
00:21:30.565 --> 00:21:32.465
and then in the layer two,

350
00:21:33.145 --> 00:21:37.145
learning the small shapes like eyes, nose, and mouth,

351
00:21:37.645 --> 00:21:41.225
and layer three, uh, you know, kind of learning the whole,

352
00:21:41.335 --> 00:21:42.865
putting all these shapes together

353
00:21:42.925 --> 00:21:44.585
and learning the face as an object.

354
00:21:45.165 --> 00:21:48.025
Um, so, so that's how the, you know,

355
00:21:48.465 --> 00:21:50.425
hierarchical learning happens in deep learning.

356
00:21:56.555 --> 00:21:56.775
Um,

357
00:22:05.035 --> 00:22:07.815
So, uh, as I said earlier, like, you know, um,

358
00:22:09.035 --> 00:22:10.595
I think we covered one, like lack

359
00:22:10.595 --> 00:22:12.355
of domain specific feature engineering is

360
00:22:12.355 --> 00:22:13.395
one of the consideration.

361
00:22:13.805 --> 00:22:17.235
While identifying deep learning problems, um, availability

362
00:22:17.255 --> 00:22:18.795
of compute is also a big one.

363
00:22:19.255 --> 00:22:20.515
Um, so, uh,

364
00:22:21.455 --> 00:22:24.795
so deep learning problems inherently require a lot of, uh,

365
00:22:24.795 --> 00:22:25.795
computational power.

366
00:22:26.495 --> 00:22:29.315
Um, so, so that's something, um, you need

367
00:22:29.315 --> 00:22:32.755
to keep in mind if you are trying to run a deal model, um,

368
00:22:33.575 --> 00:22:36.555
on, on your laptop, you know, uh, versus, you know,

369
00:22:36.555 --> 00:22:41.075
you have access to an, an AWS EC2 instance, for example, um,

370
00:22:41.505 --> 00:22:45.955
that, uh, you know, um, that is something to consider.

371
00:22:46.015 --> 00:22:48.035
So, so when you're trying to solve these problems,

372
00:22:48.455 --> 00:22:50.635
do you have that compute needed, uh,

373
00:22:50.635 --> 00:22:51.755
even if you have the data?

374
00:22:53.255 --> 00:22:56.315
Um, so, and,

375
00:22:56.655 --> 00:22:59.075
and deep learning, like, you know, the concept

376
00:22:59.335 --> 00:23:02.235
of it existed since eighties, uh,

377
00:23:02.375 --> 00:23:05.195
but it became popular more recently.

378
00:23:05.455 --> 00:23:09.315
Um, do you know why, uh, any, any, any takers there?

379
00:23:09.345 --> 00:23:11.555
Like, you know, uh, some history here,

380
00:23:11.895 --> 00:23:13.955
why it became popular intuition into why,

381
00:23:14.455 --> 00:23:16.915
why deep planning is so big thing today?

382
00:23:21.265 --> 00:23:26.155
More data, more compute. Awesome. Yeah, yeah. Um, what else?

383
00:23:35.435 --> 00:23:39.395
Yeah, yeah, yeah. I think these are all right answers.

384
00:23:41.065 --> 00:23:44.005
Um, uh, when we go to CNN's,

385
00:23:44.005 --> 00:23:45.525
I'll talk about this a little bit.

386
00:23:46.185 --> 00:23:49.405
Um, deep learning was, became popular through CNNs,

387
00:23:49.645 --> 00:23:52.365
actually, um, uh, convolutional neur networks.

388
00:23:52.505 --> 00:23:56.805
And, um, there was a paper in 2012 called AlexNet.

389
00:23:56.865 --> 00:23:58.365
Uh, you guys should go back

390
00:23:58.365 --> 00:24:00.005
and read it, uh, on your own time.

391
00:24:00.105 --> 00:24:01.925
But, uh, that sort

392
00:24:01.925 --> 00:24:05.805
of popularized the whole deep learning, uh, era.

393
00:24:06.545 --> 00:24:10.085
Um, and, um, there are several things

394
00:24:10.085 --> 00:24:11.285
that were introduced in the paper.

395
00:24:11.385 --> 00:24:12.765
One is the architecture itself,

396
00:24:13.305 --> 00:24:16.885
but the, the availability of this image net data set, uh,

397
00:24:16.885 --> 00:24:20.765
which is a huge data set that is available for, um,

398
00:24:21.495 --> 00:24:22.925
image recognition tasks.

399
00:24:23.545 --> 00:24:27.765
Uh, and then, uh, the whole, um, popularity

400
00:24:27.865 --> 00:24:30.285
of cloud computing at that point of time.

401
00:24:30.785 --> 00:24:33.645
Um, so I think cloud computing is becoming bigger

402
00:24:33.665 --> 00:24:37.205
and bigger, like around that timeframe, like 2012 ish,

403
00:24:37.585 --> 00:24:38.725
um, or even earlier.

404
00:24:39.265 --> 00:24:42.325
So, so those are some things that came together, um,

405
00:24:42.505 --> 00:24:46.205
and played a massive role in popularizing deep learning, um,

406
00:24:46.665 --> 00:24:48.805
uh, um, from, from that timeframe.

407
00:24:53.795 --> 00:24:54.285
Awesome.

408
00:25:01.925 --> 00:25:04.225
So, quick, quick overview of like, you know, how,

409
00:25:04.445 --> 00:25:07.545
what's the major difference between, um,

410
00:25:08.175 --> 00:25:10.225
deep learning versus in your network?

411
00:25:10.485 --> 00:25:12.305
As I said, in a neur network,

412
00:25:12.525 --> 00:25:15.745
you can have like an input layer, uh,

413
00:25:15.885 --> 00:25:20.345
and you combine inputs through, uh, several transformations

414
00:25:20.345 --> 00:25:23.745
and activations, and you create an output, um, layer

415
00:25:24.925 --> 00:25:27.745
in a simplistic neur network, you can have, like, you know,

416
00:25:27.805 --> 00:25:31.625
one input layer and one output layer and nothing happening.

417
00:25:31.725 --> 00:25:34.505
So you are just combining all the outputs in one go.

418
00:25:35.555 --> 00:25:37.495
But deep learning is essentially taking this

419
00:25:37.755 --> 00:25:41.535
and doing this several times, uh, in sequence

420
00:25:41.675 --> 00:25:45.415
or in some, in some networks you're also doing in parallel.

421
00:25:45.875 --> 00:25:49.415
Um, so, um, I think this, this diagram that you're seeing

422
00:25:49.625 --> 00:25:53.735
below is, is inception at Google net architecture, uh,

423
00:25:53.735 --> 00:25:56.735
which we'll look at later, but, um, uh,

424
00:25:56.915 --> 00:26:00.255
but essentially that's the whole big deal about, you know,

425
00:26:00.475 --> 00:26:01.495
uh, deep planning.

426
00:26:01.605 --> 00:26:03.415
It's the depth and complexity.

427
00:26:04.665 --> 00:26:08.005
Um, so there are multiple layers, um, whereas

428
00:26:08.585 --> 00:26:10.885
in neur networks, there is, it's shallow

429
00:26:11.305 --> 00:26:15.085
and, uh, with only, uh, one, uh, or no hidden layer.

430
00:26:15.825 --> 00:26:17.205
Um, um,

431
00:26:17.625 --> 00:26:20.855
and that gives advantage for deep learning,

432
00:26:21.085 --> 00:26:25.335
deep neural networks to learn hierarchical representations.

433
00:26:27.435 --> 00:26:32.185
Um, um, also, as I said,

434
00:26:32.185 --> 00:26:34.345
representation learning is another big thing.

435
00:26:34.525 --> 00:26:37.665
So, uh, deep learning emphasizes automatic feature

436
00:26:37.665 --> 00:26:41.425
extraction or representation, learning from raw data.

437
00:26:42.245 --> 00:26:44.105
Uh, so they're designed to learn

438
00:26:44.105 --> 00:26:46.745
and discover relevant features, uh,

439
00:26:47.185 --> 00:26:49.665
directly from the input data, uh, reducing the need

440
00:26:49.725 --> 00:26:54.465
for manual feature engineering, uh, workflows, um,

441
00:26:55.365 --> 00:26:59.625
and, uh, performance wise, like deep learning has like

442
00:27:00.185 --> 00:27:02.825
demonstrated exceptional performance in various domains,

443
00:27:02.825 --> 00:27:04.385
whether it's NLP

444
00:27:04.445 --> 00:27:08.865
or cv, uh, often sur surpassing, like, you know, uh,

445
00:27:09.005 --> 00:27:11.785
all the traditional, uh, ML approaches.

446
00:27:12.845 --> 00:27:16.765
Uh, this is, again, looking at, looking back at some

447
00:27:16.765 --> 00:27:18.765
of the slides earlier, this is new to the fact

448
00:27:18.765 --> 00:27:20.525
that they can learn, take advantage

449
00:27:20.785 --> 00:27:22.005
of large amounts of data.

450
00:27:22.705 --> 00:27:27.525
Uh, they can capture complex relationships, um, and, uh,

451
00:27:27.745 --> 00:27:31.045
but they also require like a lot of computation to do this.

452
00:27:34.155 --> 00:27:37.335
Um, interpretability wise, deep learning, uh,

453
00:27:37.335 --> 00:27:39.055
models are less interpretable.

454
00:27:39.395 --> 00:27:40.855
Uh, they're like a black box.

455
00:27:41.515 --> 00:27:45.935
Um, but, uh, you know, if you take a neural network compared

456
00:27:45.935 --> 00:27:49.215
to deep learning, uh, it's, it's a bit more interpretable,

457
00:27:49.635 --> 00:27:51.415
uh, than a deep neural network.

458
00:27:51.755 --> 00:27:55.135
So, um, uh, that's something to keep in mind in general.

459
00:27:55.515 --> 00:27:59.055
Uh, if you want interpretable, don't go with any of this.

460
00:27:59.575 --> 00:28:02.815
Probably, uh, uh, uh, linear, uh, models

461
00:28:02.995 --> 00:28:06.695
or tree based models, uh, like logistic regressions or, or,

462
00:28:06.875 --> 00:28:08.255
or random forest,

463
00:28:08.395 --> 00:28:10.095
or those are probably a better approach

464
00:28:10.195 --> 00:28:11.415
for interpretability.

465
00:28:15.065 --> 00:28:18.155
Alright, let me take some questions. I see some here.

466
00:28:35.415 --> 00:28:37.735
I think, uh, they're being answered by the ta. Thank you.

467
00:28:46.405 --> 00:28:49.775
Alright, we looked at some of this earlier, like, you know,

468
00:28:50.035 --> 00:28:53.175
um, why, uh, the need for deep learning.

469
00:28:53.515 --> 00:28:58.285
Um, so, um, complex patterns, uh,

470
00:28:58.585 --> 00:29:00.845
can be, uh, learned, um, uh,

471
00:29:01.025 --> 00:29:05.445
and representations can be learned automatically, um, uh,

472
00:29:05.475 --> 00:29:06.965
through deep learning methods.

473
00:29:07.745 --> 00:29:09.365
Um, deep learning also excels

474
00:29:09.365 --> 00:29:11.165
with transfer learning and pre-trained models.

475
00:29:11.545 --> 00:29:15.485
Um, uh, I don't know if we'll look at it in this chapter,

476
00:29:15.665 --> 00:29:18.285
but maybe in, in next classes.

477
00:29:18.585 --> 00:29:19.765
So pre-trade models

478
00:29:19.905 --> 00:29:23.165
or some foundational models that are trained on huge amounts

479
00:29:23.165 --> 00:29:25.845
of data, you can essentially take those models

480
00:29:26.785 --> 00:29:30.805
and, um, use that as your starting point instead

481
00:29:30.805 --> 00:29:31.845
of starting from scratch.

482
00:29:32.825 --> 00:29:36.645
Um, and fine tune them for your own use cases like,

483
00:29:36.645 --> 00:29:37.805
you know, uh, uh,

484
00:29:38.105 --> 00:29:41.805
but, uh, our GPT models are a good example

485
00:29:41.945 --> 00:29:43.005
of pre-trained models.

486
00:29:43.515 --> 00:29:47.605
They're trained on vast amounts of, um, uh, data

487
00:29:48.545 --> 00:29:52.765
and, uh, uh, language data, uh, especially.

488
00:29:53.385 --> 00:29:55.605
And, um, you can essentially,

489
00:29:55.605 --> 00:29:57.925
if you're building a sentiment analysis model,

490
00:29:57.985 --> 00:30:01.725
so you can take bird as your, uh, starting point

491
00:30:01.985 --> 00:30:06.925
and then fine tune that based on your training data to, uh,

492
00:30:07.425 --> 00:30:10.045
to create, uh, the sentiment analysis.

493
00:30:10.585 --> 00:30:14.445
Um, so, so that's, uh, deep learning excels in the,

494
00:30:14.465 --> 00:30:17.325
in the aspect of transfer learning, uh, taking

495
00:30:17.955 --> 00:30:19.605
preexisting foundational models

496
00:30:19.825 --> 00:30:21.965
and then using it for your own use case.

497
00:30:22.825 --> 00:30:25.465
Um, uh,

498
00:30:25.765 --> 00:30:28.265
and typically that's not possible with, you know,

499
00:30:28.285 --> 00:30:30.185
if you're taking like a tree based model

500
00:30:30.205 --> 00:30:33.265
or logistic regression model, um, it's, it's,

501
00:30:33.725 --> 00:30:36.505
you can do a lot of transfer learning there.

502
00:30:36.725 --> 00:30:40.185
Uh, these models are not curable, uh,

503
00:30:40.525 --> 00:30:44.305
or, you know, uh, extendable in that sense.

504
00:30:47.625 --> 00:30:51.845
Um, again, multi-model data, uh, can be handled inherently

505
00:30:52.145 --> 00:30:55.485
and naturally, uh, with deep learning.

506
00:30:56.145 --> 00:30:58.125
Uh, so that's one of the big advantages.

507
00:30:58.145 --> 00:31:02.405
So you can handle like different unstructured sources, uh,

508
00:31:02.405 --> 00:31:05.965
across different modalities, um, to, uh,

509
00:31:06.145 --> 00:31:08.805
and you don't even have to do any feature engineering.

510
00:31:08.805 --> 00:31:11.365
You can, you can start using those sources

511
00:31:11.745 --> 00:31:14.245
and, uh, build models, um,

512
00:31:14.705 --> 00:31:16.325
as an input to deep learning models.

513
00:31:20.255 --> 00:31:23.395
Um, in addition, like, you know, um, uh,

514
00:31:23.725 --> 00:31:25.395
there are several others, like, you know,

515
00:31:25.825 --> 00:31:29.075
deep learning models can, um, you know,

516
00:31:29.515 --> 00:31:30.675
automate end-to-end tasks

517
00:31:30.675 --> 00:31:31.915
because of the fact

518
00:31:31.915 --> 00:31:33.875
that they can do representational learning.

519
00:31:34.535 --> 00:31:37.675
Uh, they're more efficient with, with lot more data.

520
00:31:39.055 --> 00:31:44.035
Um, and, uh, they're very versatile in that sense. Um, so

521
00:31:53.675 --> 00:31:53.965
cool.

522
00:31:54.165 --> 00:31:58.125
I think this is an animation slide, so let's see.

523
00:32:07.335 --> 00:32:11.735
Yeah, so, so yeah.

524
00:32:11.995 --> 00:32:16.375
So again, these are some examples of, uh, uh,

525
00:32:16.485 --> 00:32:18.655
deep learning, uh, in real life.

526
00:32:19.035 --> 00:32:23.145
Uh, so, um, for example, like, you know,

527
00:32:23.165 --> 00:32:26.705
in the first one is the autonomous driving example.

528
00:32:27.605 --> 00:32:30.945
Uh, you are getting a, the model is getting a stream of

529
00:32:32.255 --> 00:32:36.875
frames, and it is, uh, doing object,

530
00:32:37.175 --> 00:32:39.685
uh, detection and classification here.

531
00:32:40.305 --> 00:32:45.085
Um, so, so every object is, uh, you're put, uh,

532
00:32:45.085 --> 00:32:47.765
the model is putting a bonding box around it, like where

533
00:32:47.765 --> 00:32:51.365
that object is, uh, uh, across all the frames

534
00:32:51.365 --> 00:32:53.165
and then classifying what that is.

535
00:32:53.745 --> 00:32:57.885
Um, so, um, this is, uh,

536
00:32:58.435 --> 00:33:02.565
objection is one of the core examples, uh, core, uh, uh,

537
00:33:02.565 --> 00:33:05.045
examples in CNN, uh, in computer vision.

538
00:33:05.305 --> 00:33:09.365
So it's, it's a use case, uh, that is used extensively and,

539
00:33:09.505 --> 00:33:11.365
and autonomous, um, driving.

540
00:33:11.505 --> 00:33:15.405
So, so that's, uh, that's an exact real life example, uh,

541
00:33:15.405 --> 00:33:17.485
where, you know, deep learning comes into play

542
00:33:17.485 --> 00:33:19.605
through object detection and classification.

543
00:33:21.515 --> 00:33:26.415
Um, uh, if you look at the bottom, uh,

544
00:33:26.525 --> 00:33:29.495
left, that's a classic spam filter example.

545
00:33:29.715 --> 00:33:32.935
So given a bunch of text classified as spam

546
00:33:32.935 --> 00:33:37.895
or not, um, uh, in the, in the, uh, oil days,

547
00:33:37.895 --> 00:33:41.455
this used to be a good, uh, model for, you know,

548
00:33:41.875 --> 00:33:44.055
nav based classifier or something like that.

549
00:33:44.675 --> 00:33:48.125
Uh, but, um, uh, with the, uh,

550
00:33:49.765 --> 00:33:51.965
language understanding that we have from deep learning

551
00:33:52.425 --> 00:33:55.125
and, uh, transformer models and,

552
00:33:55.385 --> 00:33:59.765
and the pre-trained models, um, uh, the,

553
00:33:59.985 --> 00:34:01.605
the text could be very complex,

554
00:34:01.985 --> 00:34:05.525
and those complexities are easily better identified

555
00:34:05.525 --> 00:34:07.165
through those, uh, deep planning models.

556
00:34:07.265 --> 00:34:10.605
So, spam fitters are nowadays mostly deep planning models,

557
00:34:11.465 --> 00:34:13.445
uh, that take advantage of, um,

558
00:34:13.955 --> 00:34:15.805
some pre-trained models as well.

559
00:34:17.465 --> 00:34:21.205
Um, so other examples like, you know, uh, like, uh,

560
00:34:21.575 --> 00:34:25.765
image generation here, like, you know, taking input image

561
00:34:26.425 --> 00:34:30.885
and creating, um, uh, various versions of that image,

562
00:34:31.625 --> 00:34:34.205
um, to like, you know, whether they're talking

563
00:34:34.305 --> 00:34:35.725
or doing some sort of action.

564
00:34:36.385 --> 00:34:40.645
Um, and, uh, stock market prediction is another example,

565
00:34:41.185 --> 00:34:44.245
uh, where you're taking a sequence of, you know, past data

566
00:34:44.265 --> 00:34:46.605
and predicting what's, what's going to happen in the future.

567
00:34:47.135 --> 00:34:48.645
We'll look at some of the examples,

568
00:34:48.755 --> 00:34:51.405
like I think in coding notebook for r

569
00:34:51.405 --> 00:34:54.085
and n, we use a stock market example, uh,

570
00:34:54.105 --> 00:34:55.245
if I remember correctly.

571
00:34:58.165 --> 00:34:59.905
All right, uh, moving on.

572
00:35:12.005 --> 00:35:15.175
Okay. So, as I said, uh, so these are the three kinds

573
00:35:15.175 --> 00:35:18.615
of networks we'll look at in depth, uh, in this class.

574
00:35:19.355 --> 00:35:22.135
Um, uh, feed forward neur networks, um,

575
00:35:22.915 --> 00:35:27.055
or, uh, FNN, uh, convolution, neur networks,

576
00:35:27.355 --> 00:35:28.775
uh, CNNs.

577
00:35:28.775 --> 00:35:32.975
These are, uh, heavily used in the computer vision space.

578
00:35:33.555 --> 00:35:38.325
Um, image, uh, recognition, object detection, um,

579
00:35:38.785 --> 00:35:42.205
object segmentation, kind of use cases, um,

580
00:35:43.695 --> 00:35:47.235
and RN ns or, or recurrent neural networks.

581
00:35:47.775 --> 00:35:50.675
Um, a lot of usage in the NLP

582
00:35:51.175 --> 00:35:54.995
or sequential data, like, you know, even stock market data,

583
00:35:56.055 --> 00:35:58.235
um, uh, language understanding.

584
00:35:58.495 --> 00:36:02.435
So we look at, you know, different, uh, aspects of RMS in

585
00:36:02.435 --> 00:36:04.555
that, uh, in this class as well.

586
00:36:16.685 --> 00:36:19.195
Lemme check, uh, there questions.

587
00:36:35.445 --> 00:36:39.295
Alright, um, uh, you might have gone through, uh,

588
00:36:39.875 --> 00:36:41.975
the loss functions in previous classes.

589
00:36:42.115 --> 00:36:43.295
So let's quickly recap.

590
00:36:43.835 --> 00:36:46.175
Um, uh, 'cause we'll, we'll be using some

591
00:36:46.175 --> 00:36:47.855
of those concepts in this class.

592
00:36:48.635 --> 00:36:52.545
So, um, maybe, um, uh,

593
00:36:52.545 --> 00:36:56.755
someone can tell me, uh, you know, uh,

594
00:36:57.455 --> 00:36:59.355
why we need a loss function, uh,

595
00:36:59.455 --> 00:37:01.075
or, uh, type in your answers.

596
00:37:01.295 --> 00:37:05.075
Uh, I wanna understand like, you know, um, if you guys, uh,

597
00:37:05.385 --> 00:37:07.435
know clearly why we use a loss function.

598
00:37:44.785 --> 00:37:47.435
Yeah, I think, uh, mostly right answers there.

599
00:37:47.655 --> 00:37:52.015
So, yeah, so

600
00:37:55.005 --> 00:37:57.495
when you are learning the network, you have a,

601
00:37:58.075 --> 00:38:00.095
the network is trying to predict something,

602
00:38:00.815 --> 00:38:03.925
and then there is a true value.

603
00:38:04.865 --> 00:38:06.285
So loss function is trying

604
00:38:06.285 --> 00:38:08.645
to minimize the gap between these two.

605
00:38:09.305 --> 00:38:12.445
So the network is trying to learn, um,

606
00:38:13.825 --> 00:38:16.085
as close to true as possible.

607
00:38:16.985 --> 00:38:19.925
So, so that's, that's a whole essence of loss function.

608
00:38:20.995 --> 00:38:25.855
Um, and, um, it's

609
00:38:27.035 --> 00:38:28.735
not an evaluation metric,

610
00:38:28.795 --> 00:38:33.775
but it's mostly, uh, a way for network to optimize, uh,

611
00:38:34.355 --> 00:38:39.005
the, the model, uh, so that we are learning things

612
00:38:39.265 --> 00:38:41.605
as close to true as possible rather than,

613
00:38:41.825 --> 00:38:43.045
uh, you know, missing those.

614
00:38:43.745 --> 00:38:47.045
So, with that, uh, in mind, uh,

615
00:38:47.235 --> 00:38:49.165
what are some loss functions, uh,

616
00:38:53.695 --> 00:38:54.425
that, you know,

617
00:39:02.485 --> 00:39:02.775
mean?

618
00:39:02.955 --> 00:39:06.285
AB error, MSC

619
00:39:09.685 --> 00:39:10.795
cross entropy.

620
00:39:19.565 --> 00:39:21.125
Hmm, okay. MSC.

621
00:39:40.485 --> 00:39:42.695
Cool. Um, so I think those are good starting points.

622
00:39:43.115 --> 00:39:47.965
Um, um, I will put all of these three in the same category.

623
00:39:48.035 --> 00:39:50.765
What, what kind of problems do, are they used to solve

624
00:39:50.865 --> 00:39:53.725
for R-M-S-E-M-A-E-M-S-E kind of losses?

625
00:39:57.715 --> 00:40:00.605
Yeah, so regression problems where you have,

626
00:40:00.625 --> 00:40:03.285
you're predicting, uh, some sort of continuous value

627
00:40:04.555 --> 00:40:07.735
and, uh, for cross entropy.

628
00:40:08.075 --> 00:40:10.295
Uh, so there is, like, you know,

629
00:40:10.295 --> 00:40:14.925
there is a binary cross entropy, uh, which is used for,

630
00:40:15.825 --> 00:40:18.365
um, classification problems, like,

631
00:40:18.365 --> 00:40:20.165
especially binary classification.

632
00:40:21.375 --> 00:40:25.795
And the, there is also categorical cross entropy, um,

633
00:40:26.085 --> 00:40:29.875
which is, uh, an extension of binary cross entropy, uh,

634
00:40:30.405 --> 00:40:32.795
where you use like, you know, uh,

635
00:40:32.815 --> 00:40:37.115
for multi-class classification problems, um,

636
00:40:41.215 --> 00:40:42.755
uh, bonus.

637
00:40:43.095 --> 00:40:47.075
Uh, so let's say your, instead

638
00:40:47.315 --> 00:40:51.785
of predicting, so you looked at, we looked at, you know,

639
00:40:51.785 --> 00:40:55.185
what kind of losses we need for regression, we, uh,

640
00:40:55.295 --> 00:40:57.665
what kind of losses we need for classification.

641
00:40:58.565 --> 00:41:00.985
Uh, let's say instead of, you know, these kind of problems,

642
00:41:00.985 --> 00:41:02.905
you're trying to predict a distribution, like, you know,

643
00:41:03.175 --> 00:41:07.505
like, uh, you're taking a probability distribution as input

644
00:41:07.525 --> 00:41:10.985
and trying to predict another probability distribution.

645
00:41:11.485 --> 00:41:14.385
Uh, do you know what kind of loss you would use in

646
00:41:14.385 --> 00:41:15.825
that particular scenario?

647
00:41:31.185 --> 00:41:31.305
I,

648
00:41:45.745 --> 00:41:50.165
So there is a loss called KL divergence, um,

649
00:41:50.495 --> 00:41:55.005
which kind of, uh, looks at, um, you know,

650
00:41:55.095 --> 00:41:57.005
takes two probability distributions

651
00:41:57.065 --> 00:42:01.485
and looks at the difference between the, uh, uh, two losses.

652
00:42:02.385 --> 00:42:04.725
Um, so that's, that's the kind of loss

653
00:42:04.725 --> 00:42:06.885
that you would use in those kind of scenarios.

654
00:42:07.545 --> 00:42:11.525
Um, so let's quickly go back to the slides, see what else?

655
00:42:12.745 --> 00:42:15.375
Um, um,

656
00:42:15.945 --> 00:42:18.815
there are several other losses like, you know, even like,

657
00:42:19.275 --> 00:42:24.165
uh, the, the existing MSE losses,

658
00:42:24.605 --> 00:42:27.845
binary losses are kind of, um, modified

659
00:42:27.945 --> 00:42:29.165
for a given use case.

660
00:42:29.745 --> 00:42:34.505
Uh, like when you do, um, um, recommendations,

661
00:42:34.505 --> 00:42:38.905
for example, um, we use, uh, uh, a loss called,

662
00:42:39.205 --> 00:42:40.825
uh, triplet loss.

663
00:42:41.645 --> 00:42:45.025
Um, so, uh, um, uh,

664
00:42:45.725 --> 00:42:49.745
and when there is lot of imbalance in the data sets,

665
00:42:49.845 --> 00:42:51.665
for example, like, you know, when you want

666
00:42:51.665 --> 00:42:53.945
to give more weightage to certain classes,

667
00:42:54.675 --> 00:42:57.105
there is a special kind of loss called focal loss.

668
00:42:57.725 --> 00:43:02.395
Um, so, so there are, again, uh, the choice

669
00:43:02.415 --> 00:43:05.805
of loss function depends on, um,

670
00:43:06.315 --> 00:43:08.325
what particular problem you're solving,

671
00:43:08.355 --> 00:43:10.245
what are the characteristics of that problem.

672
00:43:10.785 --> 00:43:12.245
But these are the base ones

673
00:43:12.245 --> 00:43:14.325
that you would use on a day-to-day basis, like,

674
00:43:14.325 --> 00:43:15.805
you know, BC or MSC.

675
00:43:16.265 --> 00:43:19.165
Uh, you never go wrong with, you know, choosing one

676
00:43:19.205 --> 00:43:21.805
or the other for, for most of the problems involving

677
00:43:22.355 --> 00:43:24.005
regressions or classifications.

678
00:43:24.105 --> 00:43:27.805
But, uh, you might want to look into more advanced losses,

679
00:43:28.505 --> 00:43:30.685
um, uh, which is a bit out of scope

680
00:43:30.685 --> 00:43:34.645
of this particular class, but, uh, um, something you,

681
00:43:34.645 --> 00:43:35.805
you can read on yourself,

682
00:43:35.805 --> 00:43:38.485
like there is a paper on loss functions itself.

683
00:43:38.745 --> 00:43:41.845
So, so, um, so, so yeah, just want

684
00:43:41.845 --> 00:43:43.605
to give you some, some knowledge there.

685
00:43:44.425 --> 00:43:44.645
Um,

686
00:43:50.885 --> 00:43:51.225
all right.

687
00:43:51.645 --> 00:43:52.665
So let's see.

688
00:43:56.835 --> 00:44:01.375
Um, what do also quickly recap, uh, gradient descent, um,

689
00:44:03.065 --> 00:44:07.085
uh, it's essentially an algorithm, uh, used

690
00:44:07.105 --> 00:44:08.285
to train the models.

691
00:44:09.185 --> 00:44:13.925
Um, and, uh, the way this algorithm works is, um,

692
00:44:14.825 --> 00:44:19.325
it ly updates, um, the network weights, um,

693
00:44:19.545 --> 00:44:21.205
and, um, biases.

694
00:44:22.265 --> 00:44:26.205
Um, so it starts by initializing weights

695
00:44:26.205 --> 00:44:30.245
and biases for, uh, a network with random values.

696
00:44:31.025 --> 00:44:32.325
Uh, these are initial values.

697
00:44:32.865 --> 00:44:36.125
Uh, this was a starting point for the optimization process,

698
00:44:37.465 --> 00:44:39.645
so maybe I can right here.

699
00:44:39.825 --> 00:44:41.845
So initialization

700
00:44:46.535 --> 00:44:50.835
and then, uh, the forward propagation is,

701
00:44:51.375 --> 00:44:56.325
is done through the network, so forward

702
00:44:58.835 --> 00:45:03.735
propagation, and based on

703
00:45:03.735 --> 00:45:06.015
this, you'll have some predicted value, right?

704
00:45:07.855 --> 00:45:10.035
And so now that you have the predicted value

705
00:45:10.035 --> 00:45:12.875
and true value, you calculate the loss.

706
00:45:16.945 --> 00:45:21.205
And then, um, once the loss is calculated, uh,

707
00:45:21.625 --> 00:45:23.685
the back propagation is performed.

708
00:45:26.035 --> 00:45:31.025
Um, so that's essentially the, the four step process of,

709
00:45:31.165 --> 00:45:34.505
um, uh, gradient descent.

710
00:45:34.925 --> 00:45:38.625
So, uh, initialize the network with some random rates, uh,

711
00:45:38.765 --> 00:45:40.745
do a forward propagation through the network

712
00:45:40.965 --> 00:45:44.785
and calculate the outputs or the predicted values, uh,

713
00:45:44.925 --> 00:45:48.305
and then calculate, calculate the loss between the predicted

714
00:45:48.965 --> 00:45:52.105
and the true values based on the loss function chosen.

715
00:45:52.885 --> 00:45:54.785
And then once you have the laws, you back,

716
00:45:54.815 --> 00:45:56.065
back propagate the laws.

717
00:45:57.205 --> 00:46:00.145
Um, so maybe you already know this.

718
00:46:00.205 --> 00:46:04.655
So what is the, um, uh,

719
00:46:05.375 --> 00:46:08.895
calculus rule that's, uh, that's used for back propagation?

720
00:46:09.485 --> 00:46:11.095
Yeah. Chain rule. Yeah. Yeah.

721
00:46:11.515 --> 00:46:14.575
Uh, cool.

722
00:46:14.795 --> 00:46:18.015
Um, let's, let's look at some of the,

723
00:46:18.235 --> 00:46:21.655
or maybe we can recap, um, some of the

724
00:46:22.165 --> 00:46:23.935
math here if possible.

725
00:46:23.995 --> 00:46:25.015
So, let's see. Um,

726
00:46:39.315 --> 00:46:41.135
uh, let me see if I can

727
00:46:45.295 --> 00:46:46.285
whiteboard this.

728
00:46:47.635 --> 00:46:51.535
Um, so essentially, so you have your

729
00:46:52.525 --> 00:46:53.975
loss, as you know.

730
00:46:54.195 --> 00:46:59.175
Um, let's say it's, um, MSC loss of

731
00:47:00.275 --> 00:47:01.845
true and predicted.

732
00:47:04.865 --> 00:47:06.685
So it's essentially a squared error.

733
00:47:07.625 --> 00:47:11.555
So, so you have your, um,

734
00:47:12.855 --> 00:47:13.075
um,

735
00:47:25.135 --> 00:47:26.245
sorry, gimme one second.

736
00:47:32.905 --> 00:47:36.285
So the chain rule states that, um, you can, uh,

737
00:47:36.355 --> 00:47:41.045
take partial ative of, you know, the, the output,

738
00:47:41.985 --> 00:47:44.365
um, with respect to input,

739
00:47:45.065 --> 00:47:49.635
and then you can take the, uh, partial ative of input

740
00:47:49.635 --> 00:47:50.795
with respect to weights.

741
00:47:52.045 --> 00:47:55.705
Um, and, um, so

742
00:47:57.005 --> 00:47:58.185
you have your loss

743
00:48:00.795 --> 00:48:02.045
with respect to output.

744
00:48:03.615 --> 00:48:06.875
Um, so, so that's your,

745
00:48:15.455 --> 00:48:20.025
so, so that's how, uh, a loss, uh,

746
00:48:20.245 --> 00:48:23.465
is used to calculate the, the weights.

747
00:48:24.045 --> 00:48:26.985
And this loss is essentially propagated during the,

748
00:48:27.765 --> 00:48:29.345
um, the update process.

749
00:48:29.525 --> 00:48:33.665
So you have your weight o uh, weight, new, equal to

750
00:48:34.375 --> 00:48:38.435
weight, old, minus some sort of

751
00:48:39.315 --> 00:48:44.145
learning rate times, whatever this gradient is,

752
00:48:45.895 --> 00:48:48.075
uh, which is what your input here.

753
00:48:48.695 --> 00:48:51.555
Um, so, so that's, uh, essentially how, you know,

754
00:48:51.855 --> 00:48:55.115
in every network step, you apply the chain rule,

755
00:48:55.945 --> 00:48:58.915
calculate the gradient of the loss with respective weights,

756
00:48:59.855 --> 00:49:03.715
and then use that to update the weights,

757
00:49:04.055 --> 00:49:05.275
uh, for each of the steps.

758
00:49:06.055 --> 00:49:10.835
Um, um, so that's a high level how, um,

759
00:49:11.055 --> 00:49:13.755
you know, a gradient isn't works, um,

760
00:49:14.185 --> 00:49:15.915
from a mathematical perspective.

761
00:49:23.235 --> 00:49:25.595
Um, again, some of the things we already talked about.

762
00:49:25.895 --> 00:49:30.395
Um, so, uh, this is, uh, the diagram here is,

763
00:49:30.495 --> 00:49:33.955
is a 2D representation of, you know, how the loss changes

764
00:49:34.065 --> 00:49:36.595
with respect to one of the weights, um,

765
00:49:36.615 --> 00:49:39.035
and how it reaches a minimum.

766
00:49:40.245 --> 00:49:44.705
Um, so as you can see the steps, you do the initialization

767
00:49:45.405 --> 00:49:48.785
of weights and biases, forward prop, calculate loss back,

768
00:49:48.815 --> 00:49:52.625
back propagation, uh, update the weights, um,

769
00:49:52.765 --> 00:49:55.825
and then kind of repeat the steps two through five, um,

770
00:49:56.075 --> 00:49:58.305
until there is some condition that's being met,

771
00:49:58.305 --> 00:50:01.345
that the loss is not reducing by much,

772
00:50:01.925 --> 00:50:03.505
or, you know, uh,

773
00:50:03.805 --> 00:50:06.745
or, you know, there is a divergence between training

774
00:50:06.765 --> 00:50:09.225
and validation losses, things like that.

775
00:50:09.245 --> 00:50:11.825
So the different stopping criteria that you can use

776
00:50:11.885 --> 00:50:14.305
to stop the learning when you think

777
00:50:14.305 --> 00:50:16.865
that it reached a, uh, minimum.

778
00:50:18.575 --> 00:50:18.795
Um,

779
00:50:24.175 --> 00:50:24.475
all right.

780
00:50:24.615 --> 00:50:27.565
So let's talk quickly talk about activation functions.

781
00:50:28.585 --> 00:50:31.365
Um, um,

782
00:50:33.305 --> 00:50:34.965
why do we need activation functions?

783
00:50:35.105 --> 00:50:37.325
Uh, any takers? Uh, just curious.

784
00:50:55.935 --> 00:50:59.755
So we are trying to model complex, uh, problems, right?

785
00:50:59.755 --> 00:51:02.235
Like, for example, you know, object detection,

786
00:51:02.285 --> 00:51:05.355
phase recognition, or even learning from,

787
00:51:06.425 --> 00:51:10.915
from text, um, is, is, is a complex non-linear problem.

788
00:51:11.705 --> 00:51:13.315
It's not very linear, like, you know,

789
00:51:13.315 --> 00:51:14.435
house price prediction.

790
00:51:15.215 --> 00:51:19.635
So, so to add that non-linear to the network, uh,

791
00:51:19.635 --> 00:51:20.755
and a lot of good answers here.

792
00:51:20.855 --> 00:51:23.435
So, uh, we use functions

793
00:51:23.895 --> 00:51:26.435
and transformations called activation functions.

794
00:51:26.615 --> 00:51:29.595
Um, there are several, um, like, you know, some

795
00:51:29.595 --> 00:51:31.755
of the things that you're seeing on the page here, like,

796
00:51:31.755 --> 00:51:36.435
you know, sigmoid, um, tan edge, relu, um,

797
00:51:37.065 --> 00:51:41.195
Galu or leaky loo, for example, uh, soft max,

798
00:51:41.365 --> 00:51:44.475
which there the bunch of, uh, activation functions.

799
00:51:44.475 --> 00:51:46.595
There is a whole research area dedicated

800
00:51:46.615 --> 00:51:48.195
to activation functions itself,

801
00:51:49.415 --> 00:51:53.835
and we choose the ones that are useful for a given scenario,

802
00:51:54.105 --> 00:51:57.315
like, um, uh, we'll get into some intuition, how

803
00:51:57.315 --> 00:51:59.755
to choose them, uh, in later stages.

804
00:51:59.975 --> 00:52:03.915
But, uh, at a high level, uh, it's important to know

805
00:52:04.025 --> 00:52:06.035
what these activation functions are doing.

806
00:52:06.385 --> 00:52:09.995
Like, for example, if you take sigmoid here, like

807
00:52:10.105 --> 00:52:13.915
what would be the output range for this activation function?

808
00:52:23.605 --> 00:52:26.125
So it's always between zero and one.

809
00:52:26.905 --> 00:52:31.005
Um, and for tanh, um, uh,

810
00:52:31.365 --> 00:52:33.845
likewise it would be centered around zero.

811
00:52:34.665 --> 00:52:37.885
So it would be between negative one and plus one.

812
00:52:38.785 --> 00:52:42.805
So if you're trying to do a zero centric activation, uh,

813
00:52:43.395 --> 00:52:48.085
then probably tanh is, is is the reasonable choice here.

814
00:52:48.545 --> 00:52:51.965
Uh, if you're trying to use classify something as binary

815
00:52:52.145 --> 00:52:55.725
or not, typically sigmoid activations are used in, um,

816
00:52:56.265 --> 00:52:59.685
you know, uh, in, uh, classification problems,

817
00:52:59.925 --> 00:53:01.125
binary classification problems.

818
00:53:01.825 --> 00:53:06.205
Um, um, so if you're trying to do like a on off kind of

819
00:53:06.965 --> 00:53:10.485
scenario, um, uh, true false kind of scenario, that's

820
00:53:10.485 --> 00:53:12.165
where sigmoid activation is come into play.

821
00:53:13.025 --> 00:53:16.285
Um, uh, relu, uh, is an interesting one.

822
00:53:16.425 --> 00:53:20.125
So, so relu is max of zero x.

823
00:53:20.625 --> 00:53:22.045
Uh, so it's always positive.

824
00:53:22.145 --> 00:53:26.525
So it kind of caps, it caps, uh, a function like that.

825
00:53:27.145 --> 00:53:29.165
Um, so it doesn't go negative.

826
00:53:29.705 --> 00:53:34.685
Um, so, um, so it's used to, uh,

827
00:53:34.755 --> 00:53:38.325
introduce non-linear to the network without much complexity

828
00:53:38.325 --> 00:53:40.405
that is, uh, like, you know, like sigmoid

829
00:53:40.405 --> 00:53:43.565
and tan hedge functions are complex, uh, to calculate.

830
00:53:43.645 --> 00:53:45.125
So, but relu is super fast.

831
00:53:45.705 --> 00:53:49.205
So, so relu is introduced to, to mitigate some

832
00:53:49.205 --> 00:53:52.885
of the complex piece, um, but also introduce non-linearity,

833
00:53:53.875 --> 00:53:57.255
and galu is, is another, uh, modification of,

834
00:53:57.475 --> 00:53:58.775
uh, relu function.

835
00:53:59.235 --> 00:54:03.375
Uh, for example, um, I think, uh, galu is, you know,

836
00:54:03.375 --> 00:54:06.895
something like instead of Klu making it, you know, um,

837
00:54:07.455 --> 00:54:11.575
a a zero, uh, for negative values, um, uh,

838
00:54:11.755 --> 00:54:16.645
so Galu uses something like X into five x, uh, where five

839
00:54:16.665 --> 00:54:20.405
of X can be some function, like, you know, like, you know,

840
00:54:20.635 --> 00:54:24.835
some, um, sigmoid, uh,

841
00:54:24.975 --> 00:54:27.155
or, you know, tanh or whatever.

842
00:54:27.175 --> 00:54:31.195
So it kind of weights the values, um, uh,

843
00:54:31.195 --> 00:54:32.515
instead of gating them.

844
00:54:32.695 --> 00:54:37.275
So, so, so relu kind of gates them like anything below, uh,

845
00:54:37.465 --> 00:54:38.715
zero is gated.

846
00:54:39.295 --> 00:54:42.835
Uh, galu is kind of weights them instead of getting them by,

847
00:54:42.935 --> 00:54:44.955
by a factor of another function.

848
00:54:45.495 --> 00:54:50.075
Um, uh, with respect to that, uh, input value, um,

849
00:54:51.495 --> 00:54:54.235
um, there is also versions like, you know, uh, leak

850
00:54:54.825 --> 00:54:58.395
that was introduced to, uh, to, uh, take care

851
00:54:58.515 --> 00:55:01.675
of the negative effects of, um, alu functions.

852
00:55:02.215 --> 00:55:05.795
Uh, for example, um, softmax, you, you guys have,

853
00:55:05.965 --> 00:55:09.315
might have probably, uh, uh, known, known about that.

854
00:55:09.495 --> 00:55:12.435
Um, it's, it's, it's a extension

855
00:55:12.435 --> 00:55:13.955
of sigmoid function, essentially.

856
00:55:14.055 --> 00:55:16.555
So when you have multiple classes, uh,

857
00:55:16.695 --> 00:55:20.315
and there are logics, uh, being produced, so softmax,

858
00:55:20.315 --> 00:55:24.675
essentially what it does is it creates probability one,

859
00:55:24.675 --> 00:55:26.635
probability two, probability three,

860
00:55:27.295 --> 00:55:30.555
and the sum of all of these will be always equal

861
00:55:30.555 --> 00:55:32.075
to a hundred percent or one.

862
00:55:32.575 --> 00:55:35.675
Um, so softmax layer essentially takes a bunch of numbers

863
00:55:36.615 --> 00:55:40.195
and puts them into, uh, a probability, uh,

864
00:55:40.405 --> 00:55:43.065
value distribution, where the sum

865
00:55:43.065 --> 00:55:45.305
of all those probabilities is always equal to one.

866
00:55:46.085 --> 00:55:48.745
Um, so that's a, that's a quick recap

867
00:55:48.765 --> 00:55:53.505
of different activation functions, um, um, that,

868
00:55:53.605 --> 00:55:55.185
uh, that are very popular.

869
00:56:01.905 --> 00:56:05.695
Cool. Alright,

870
00:56:05.785 --> 00:56:07.295
let's quickly summarize the section.

871
00:56:07.555 --> 00:56:10.215
So, um, we looked at, you know,

872
00:56:10.765 --> 00:56:12.855
what are the salient characteristics

873
00:56:12.855 --> 00:56:14.095
of deep learning problems?

874
00:56:14.975 --> 00:56:18.065
What are different, uh, uh, ways that, you know,

875
00:56:18.535 --> 00:56:22.585
deep learning problems can be identified, uh, what kind

876
00:56:22.585 --> 00:56:24.645
of areas they excel at, kind

877
00:56:24.645 --> 00:56:26.965
of unstructured data representation,

878
00:56:27.285 --> 00:56:29.565
learning end-to-end learning, lots of data,

879
00:56:29.635 --> 00:56:32.245
high dimensionality, uh, things like that.

880
00:56:32.705 --> 00:56:35.885
Uh, we looked at some real life examples where, you know,

881
00:56:35.885 --> 00:56:37.645
deep learning is being used properly.

882
00:56:38.305 --> 00:56:42.645
Um, some advantages, uh, and challenges with deep learning.

883
00:56:43.265 --> 00:56:47.765
Um, we also recapped on the loss functions, GD algorithm

884
00:56:48.145 --> 00:56:49.605
and activation functions.

885
00:56:50.225 --> 00:56:53.765
So, uh, let's a quick recap of the section we just went

886
00:56:53.765 --> 00:56:56.845
through, uh, in the next session, our learning object is

887
00:56:56.845 --> 00:56:59.645
to go through, uh, feedforward neural networks.

888
00:57:00.735 --> 00:57:05.035
Um, so let's take a quick five minute break, uh,

889
00:57:05.035 --> 00:57:06.435
before going to the next session.

890
00:57:07.215 --> 00:57:09.075
Uh, so let's stand 10 now.

891
00:57:09.295 --> 00:57:12.515
Uh, uh, uh, so let's, uh, start at 10 15

892
00:57:13.255 --> 00:57:16.675
and, uh, we'll look at we power Neil Networks.

893
00:57:21.135 --> 00:57:24.105
Alright, hopefully everyone is back. Uh, let's get started.

894
00:57:25.315 --> 00:57:26.615
Um, cool, uh,

895
00:57:26.625 --> 00:57:31.135
we'll dive into f in this particular section of the class.

896
00:57:37.845 --> 00:57:39.825
So a quick section agenda.

897
00:57:55.195 --> 00:57:57.845
Yeah, so, uh, we'll talk about, you know, uh,

898
00:57:57.845 --> 00:57:59.765
quickly introduce fns, uh,

899
00:57:59.765 --> 00:58:02.525
what is the underlying principle there, uh,

900
00:58:02.785 --> 00:58:05.525
how different layers in f and n works, um,

901
00:58:05.865 --> 00:58:09.605
and, you know, some limitations, advantages, um,

902
00:58:09.605 --> 00:58:11.245
applications of F and n.

903
00:58:11.705 --> 00:58:13.725
Uh, and then we'll, we'll wrap it up

904
00:58:13.845 --> 00:58:17.685
with a coding walkthrough of an f and n on a dataset.

905
00:58:19.325 --> 00:58:21.865
Uh, so that's a brief agenda for this section.

906
00:58:28.635 --> 00:58:31.215
Um, so as, as we talked earlier, f

907
00:58:31.215 --> 00:58:33.495
and n stands for feedforward Neural Network.

908
00:58:33.835 --> 00:58:36.535
In some places it's called FFNN, uh,

909
00:58:36.635 --> 00:58:38.775
or FNN, they, they all mean the same.

910
00:58:39.395 --> 00:58:44.215
Um, it is, uh, sometimes also referred to as MLP,

911
00:58:44.595 --> 00:58:46.055
uh, multilayer, perceptron.

912
00:58:46.315 --> 00:58:48.895
Um, it's a bit older technology,

913
00:58:49.035 --> 00:58:51.055
but, uh, it's, it's also referred as such.

914
00:58:51.715 --> 00:58:55.975
Um, So, um,

915
00:58:59.075 --> 00:59:01.705
there might be some confusion around like the,

916
00:59:01.805 --> 00:59:05.865
the naming convention, like, you know, um, if, you know,

917
00:59:06.125 --> 00:59:10.585
why is it called feet forward, uh, versus, you know, um, uh,

918
00:59:11.075 --> 00:59:15.105
since the, uh, the loss propagates backward,

919
00:59:15.105 --> 00:59:16.705
there is a back propagation there.

920
00:59:16.705 --> 00:59:19.905
So, so why the naming, uh, technology?

921
00:59:21.265 --> 00:59:26.205
So, um, the reason for the naming there is, you know,

922
00:59:26.345 --> 00:59:30.005
the information, the actual information always flows in one

923
00:59:30.005 --> 00:59:31.965
direction, uh, in this way.

924
00:59:32.585 --> 00:59:35.005
Um, and, uh, so that's,

925
00:59:35.345 --> 00:59:38.365
and there are no like recurrences, like, you know, there is

926
00:59:38.945 --> 00:59:40.925
no like information being retained

927
00:59:40.925 --> 00:59:43.725
and being passed back to a previous layer

928
00:59:44.225 --> 00:59:46.965
or to the same layer, uh, which we'll see in.

929
00:59:48.505 --> 00:59:52.245
Um, so, so the information is always passing through from,

930
00:59:52.475 --> 00:59:56.605
from, from the left to the right, uh, across the layer.

931
00:59:56.605 --> 00:59:57.965
So that's, that's why it's called

932
00:59:57.965 --> 00:59:59.925
feedforward, uh, neural network.

933
01:00:01.185 --> 01:00:03.365
Um, uh, and there are no loops

934
01:00:03.425 --> 01:00:05.365
or cycles of, uh,

935
01:00:05.365 --> 01:00:07.485
where the information is being passed back.

936
01:00:08.025 --> 01:00:09.445
Um, so, uh,

937
01:00:09.445 --> 01:00:10.725
that's the reason why they're called

938
01:00:10.725 --> 01:00:11.885
feedforward neural Networks.

939
01:00:12.425 --> 01:00:15.525
Um, uh, the back propagation there, uh,

940
01:00:15.545 --> 01:00:18.485
the confusion could also come like, Hey, the, the,

941
01:00:18.825 --> 01:00:20.605
the loss is being propagated back.

942
01:00:20.945 --> 01:00:22.365
So we are not talking about

943
01:00:22.465 --> 01:00:23.965
how the loss is being propagated.

944
01:00:23.985 --> 01:00:26.525
We are only talking about how the information moves.

945
01:00:27.065 --> 01:00:30.245
Um, so, so bap propagation essentially moves

946
01:00:30.245 --> 01:00:31.805
backward, uh, in any network.

947
01:00:32.545 --> 01:00:36.205
Um, so, so that's a separate concept compared to, you know,

948
01:00:36.205 --> 01:00:37.485
how the data is flowing through.

949
01:00:40.315 --> 01:00:43.625
Um, uh,

950
01:00:43.765 --> 01:00:48.185
and, uh, we discussed like, you know, during training, um, f

951
01:00:48.185 --> 01:00:51.545
and n learns by a process called, um, you know,

952
01:00:51.695 --> 01:00:54.385
grad indecent as the optimization algorithm.

953
01:00:54.965 --> 01:00:57.865
Um, and by adjusting the weights

954
01:00:57.865 --> 01:01:02.305
and biases, um, through the process, um, uh, using the loss,

955
01:01:02.645 --> 01:01:05.425
that's how the, all these mini weights

956
01:01:05.485 --> 01:01:09.945
and biases are learned, uh, during the, uh,

957
01:01:10.525 --> 01:01:14.745
uh, learning process, training process, uh, using the, uh,

958
01:01:14.775 --> 01:01:18.025
back appropriation technique and gradient central algorithm.

959
01:01:20.905 --> 01:01:24.005
Now, the end goal is to, uh, minimize the loss,

960
01:01:24.445 --> 01:01:29.085
whatever loss, uh, which, uh, which you choose, like,

961
01:01:29.085 --> 01:01:32.685
you know, whether it's, uh, cross entropy or MSE

962
01:01:33.385 --> 01:01:35.005
or some, some of the laws

963
01:01:35.005 --> 01:01:37.005
that are being used for a given problem.

964
01:01:37.705 --> 01:01:42.615
Um, so, uh, to recap, uh, in feed four neural networks,

965
01:01:42.615 --> 01:01:43.655
there are several layers.

966
01:01:44.275 --> 01:01:46.775
Um, there is an input layer, um,

967
01:01:47.335 --> 01:01:49.415
multiple hidden layers and an output layer.

968
01:01:50.155 --> 01:01:54.895
Um, and essentially the information flows from, you know,

969
01:01:55.045 --> 01:01:57.575
from the input layer to the output layer in one direction.

970
01:01:58.235 --> 01:02:00.175
Uh, hence the name. Um,

971
01:02:00.725 --> 01:02:05.135
they are optimized using gradient descent algorithms, uh,

972
01:02:05.135 --> 01:02:06.855
using back propagation techniques.

973
01:02:07.395 --> 01:02:10.855
Um, various losses can be used, uh, to determine

974
01:02:11.115 --> 01:02:14.055
how the predicted values are, uh,

975
01:02:14.085 --> 01:02:15.935
different from the true values

976
01:02:17.425 --> 01:02:20.805
and, um, the network cloud using the,

977
01:02:21.385 --> 01:02:22.645
the gradient dis design process.

978
01:02:23.305 --> 01:02:26.405
Um, so that's a quick overview of, you know, how f

979
01:02:26.405 --> 01:02:29.805
and n works, uh, from, you know, um,

980
01:02:30.475 --> 01:02:31.765
from a training perspective.

981
01:02:44.095 --> 01:02:47.955
Um, again, I think we looked at, you know, uh, this earlier.

982
01:02:48.375 --> 01:02:51.955
So just want to quickly, uh, recap

983
01:02:52.135 --> 01:02:54.675
how the loss is calculated with respect to each weight.

984
01:02:55.835 --> 01:02:58.555
So you have your, um,

985
01:03:03.345 --> 01:03:03.875
rule here.

986
01:03:04.015 --> 01:03:07.155
So essentially, uh, the loss is the differentiated

987
01:03:07.155 --> 01:03:08.755
with respect to each of the weights.

988
01:03:08.755 --> 01:03:12.035
So this could be your W one, uh, W2,

989
01:03:12.195 --> 01:03:13.715
W three, so on and so forth.

990
01:03:14.295 --> 01:03:16.675
Um, so for with respect to each weight, we're,

991
01:03:16.765 --> 01:03:18.395
we're doing a partial der

992
01:03:19.375 --> 01:03:22.835
and then we're essentially coming to that, uh, value

993
01:03:22.935 --> 01:03:27.515
by using these derivatives, um, uh, differentiating the laws

994
01:03:27.595 --> 01:03:30.115
with respect, output, output with respect to input,

995
01:03:30.335 --> 01:03:33.245
and then input with respect to weights, um,

996
01:03:33.745 --> 01:03:38.085
and then using those values in the, um, uh,

997
01:03:38.085 --> 01:03:39.685
weight ation function.

998
01:03:45.385 --> 01:03:48.045
Um, so, uh, that's essentially what's happening

999
01:03:48.045 --> 01:03:50.205
during the grad indecent process,

1000
01:03:58.805 --> 01:03:59.155
right?

1001
01:04:00.855 --> 01:04:04.755
Um, again, um, I think this is an animation slide.

1002
01:04:04.845 --> 01:04:06.515
Let's see. Uh,

1003
01:04:17.715 --> 01:04:22.325
yeah, so this is, uh,

1004
01:04:22.585 --> 01:04:27.125
an animation of how the different activations are used, um,

1005
01:04:27.585 --> 01:04:30.565
uh, and, uh, how data passes

1006
01:04:31.195 --> 01:04:32.805
from input to output layers.

1007
01:04:33.625 --> 01:04:37.605
So, um, um, essentially as you can see,

1008
01:04:37.605 --> 01:04:39.765
it's always forward propagating.

1009
01:04:40.425 --> 01:04:44.965
Um, there are multiple, uh, neurons in each layer,

1010
01:04:45.545 --> 01:04:49.325
uh, with, uh, which are activating at different points

1011
01:04:49.385 --> 01:04:53.645
of time, and they're calculating the transformed output, uh,

1012
01:04:53.645 --> 01:04:54.765
through that activation.

1013
01:04:55.465 --> 01:05:00.285
Um, and, um, essentially that becomes an input

1014
01:05:00.285 --> 01:05:03.125
to the next layer, uh, and so on and so forth.

1015
01:05:03.625 --> 01:05:05.765
So, um, one thing to

1016
01:05:06.625 --> 01:05:10.335
understand here is you can see all these dense connections

1017
01:05:10.335 --> 01:05:13.095
here, like, you know, um, by that I mean,

1018
01:05:13.325 --> 01:05:17.765
what I mean is every node in one layer, uh,

1019
01:05:18.065 --> 01:05:20.885
is connected to every other node in the next layer.

1020
01:05:21.995 --> 01:05:25.015
So, uh, let, let me go back to this one.

1021
01:05:25.555 --> 01:05:29.495
So you can, you can see, like, you know, um, all these,

1022
01:05:30.515 --> 01:05:33.455
uh, all permutations of, of,

1023
01:05:33.875 --> 01:05:36.215
or combinations of these connections happening

1024
01:05:36.215 --> 01:05:38.615
between every input node and the output node.

1025
01:05:39.035 --> 01:05:41.215
Uh, so that type of layer is called, you know,

1026
01:05:41.285 --> 01:05:42.535
densely connected layer.

1027
01:05:43.425 --> 01:05:48.085
Uh, and, uh, that's a characteristic of,

1028
01:05:48.305 --> 01:05:51.165
uh, feedforward neural networks, uh, is, you know,

1029
01:05:51.215 --> 01:05:53.765
every node in, in a layer is connected

1030
01:05:53.765 --> 01:05:55.405
to every other node in the next layer.

1031
01:05:56.185 --> 01:06:00.065
So essentially, uh, if, if you look at,

1032
01:06:00.445 --> 01:06:03.465
to take this particular layer, let we use a different color,

1033
01:06:04.245 --> 01:06:09.025
um, so let's call it node layer two, node one.

1034
01:06:09.725 --> 01:06:14.105
So for layer two, node one, it's inputs from

1035
01:06:15.245 --> 01:06:17.025
all these four nodes.

1036
01:06:17.925 --> 01:06:22.025
Um, so, so layer one, node one plus layer,

1037
01:06:23.005 --> 01:06:26.785
um, one node, two plus layer one, no, three

1038
01:06:27.575 --> 01:06:29.025
plus layer one node four.

1039
01:06:29.965 --> 01:06:33.705
And essentially it's using a,

1040
01:06:35.965 --> 01:06:39.695
um, activation function on all of this.

1041
01:06:40.735 --> 01:06:42.435
Um, like, you know, in this case,

1042
01:06:42.435 --> 01:06:44.755
maybe if the activation function is relu,

1043
01:06:44.815 --> 01:06:47.275
so it's using relu on, on top of all of this,

1044
01:06:47.575 --> 01:06:50.595
and then outputting some sort of value, which is your

1045
01:06:51.245 --> 01:06:52.395
layer two, node one,

1046
01:06:52.535 --> 01:06:56.715
and that becomes, again, um, an input to the next layer.

1047
01:06:57.295 --> 01:06:59.755
So each layer is a composition of nodes,

1048
01:07:00.415 --> 01:07:02.475
and, uh, each node

1049
01:07:02.695 --> 01:07:06.475
or activation calculates, uh, the activation

1050
01:07:06.575 --> 01:07:09.675
by summing up the, uh,

1051
01:07:09.945 --> 01:07:12.355
activations from its input notes

1052
01:07:12.735 --> 01:07:14.915
and applies a transformation around it,

1053
01:07:14.915 --> 01:07:16.195
which is the activation function.

1054
01:07:16.935 --> 01:07:19.755
And, uh, that becomes an input to the next layer.

1055
01:07:29.675 --> 01:07:31.635
Cool. So, um,

1056
01:07:34.735 --> 01:07:38.225
typically the input layer that represents the dimension

1057
01:07:38.225 --> 01:07:39.225
of the input vector.

1058
01:07:40.045 --> 01:07:43.905
Uh, so if your input vector is, let's say, um,

1059
01:07:44.905 --> 01:07:47.545
a 10 dimensional vector, um, so

1060
01:07:47.545 --> 01:07:49.505
that you know your input layer, the number

1061
01:07:49.505 --> 01:07:53.265
of nodes in the input layer is the dimension of the, uh,

1062
01:07:53.435 --> 01:07:54.705
input, uh, vector

1063
01:07:55.885 --> 01:07:58.665
and output layer represents the dimension of

1064
01:07:58.665 --> 01:07:59.785
what we're trying to predict.

1065
01:07:59.885 --> 01:08:04.425
So if it's a, uh, classification problem, like binary, yes

1066
01:08:04.425 --> 01:08:06.225
or no, it could be just one node.

1067
01:08:06.645 --> 01:08:09.585
Uh, if it's a multi-class classification, uh,

1068
01:08:09.805 --> 01:08:12.625
use the soft max with, uh, number of nodes equal

1069
01:08:12.625 --> 01:08:13.745
to number of classes.

1070
01:08:14.685 --> 01:08:17.645
Um, um, so, uh, input

1071
01:08:19.375 --> 01:08:19.725
layer

1072
01:08:25.625 --> 01:08:26.445
of input.

1073
01:08:29.145 --> 01:08:31.845
Uh, so, uh, let's take an example.

1074
01:08:31.945 --> 01:08:36.365
For example, let's say you are using a, uh,

1075
01:08:37.375 --> 01:08:39.005
image as an input, uh,

1076
01:08:39.145 --> 01:08:41.205
and image is essentially pixels, right?

1077
01:08:41.305 --> 01:08:45.245
So let's say you are using a image of 10 by 10 pixels,

1078
01:08:46.105 --> 01:08:49.265
uh, right?

1079
01:08:49.365 --> 01:08:53.185
So you have a hundred pixel values, so you can flatten this

1080
01:08:53.205 --> 01:08:56.305
and supply to the input, as, you know,

1081
01:08:56.505 --> 01:08:57.745
a hundred dimension vector.

1082
01:08:58.725 --> 01:09:01.825
Um, so, so that's, that's essentially how we think of input.

1083
01:09:01.965 --> 01:09:03.905
So especially when you're, in this case,

1084
01:09:03.905 --> 01:09:06.225
we're supplying an image of 10 by 10 pixels.

1085
01:09:06.725 --> 01:09:10.025
Um, so, so that's the input size a hundred dimensions

1086
01:09:10.385 --> 01:09:11.385
represent, uh, uh,

1087
01:09:11.385 --> 01:09:13.985
each dimension represents the pixel values of each of the,

1088
01:09:14.445 --> 01:09:16.225
um, uh, pixel.

1089
01:09:16.925 --> 01:09:19.185
And then, uh, in the middle layers,

1090
01:09:19.605 --> 01:09:20.785
you lose some processing.

1091
01:09:20.885 --> 01:09:23.745
The choice of how many nodes in the middle layers depends on

1092
01:09:23.745 --> 01:09:24.745
the complexity of the problem.

1093
01:09:25.615 --> 01:09:29.225
Usually there is a sort of, you know, uh, upsampling

1094
01:09:29.325 --> 01:09:32.505
and downsampling happening, uh, in the hidden layers.

1095
01:09:33.205 --> 01:09:36.665
And then, uh, the output layer, let's say you take the image

1096
01:09:36.725 --> 01:09:38.385
and you want to classify it as dog

1097
01:09:38.385 --> 01:09:40.145
or cat, it's a binary problem.

1098
01:09:40.255 --> 01:09:42.825
Then you only have one node in the output layer,

1099
01:09:43.165 --> 01:09:45.665
but let's say you want to classify it as dog, cat,

1100
01:09:45.805 --> 01:09:47.425
or you know, a rat.

1101
01:09:47.805 --> 01:09:49.465
Uh, so you have, you know, three classes.

1102
01:09:49.605 --> 01:09:53.225
So in that particular case, uh, you'll have like, you know,

1103
01:09:53.515 --> 01:09:56.305
three notes in the output layer, uh,

1104
01:09:56.475 --> 01:10:00.145
which represent the probability of, you know, a dog,

1105
01:10:00.145 --> 01:10:02.265
probability of cat, probability of cat.

1106
01:10:02.885 --> 01:10:05.865
Um, um, so these are the middle layers,

1107
01:10:06.785 --> 01:10:11.145
and then you have your hundred dimension input layer.

1108
01:10:12.065 --> 01:10:13.525
So think of, think of, you know,

1109
01:10:13.525 --> 01:10:16.445
setting up the network architecture that way.

1110
01:10:31.155 --> 01:10:33.975
Any questions, uh, uh, before we move on?

1111
01:10:40.055 --> 01:10:40.345
Cool.

1112
01:10:51.755 --> 01:10:53.215
So let's look at this example

1113
01:10:53.225 --> 01:10:55.575
where we have just one hidden layer.

1114
01:10:55.875 --> 01:11:00.295
Um, uh, in this case, you have an input layer, uh,

1115
01:11:00.525 --> 01:11:05.015
with the number of, uh, input neurons SSL to

1116
01:11:07.185 --> 01:11:08.335
three, uh,

1117
01:11:08.435 --> 01:11:12.295
and we have hidden layer with number of hidden neurons, SQL

1118
01:11:12.295 --> 01:11:13.445
to four,

1119
01:11:13.705 --> 01:11:18.125
and an output layer with just, uh, one year on.

1120
01:11:18.585 --> 01:11:21.885
Um, so, so that's the, that's the network structure

1121
01:11:22.025 --> 01:11:23.965
for this particular f and n model.

1122
01:11:25.855 --> 01:11:30.445
Uh, do you know how many, uh, uh, parameters,

1123
01:11:31.065 --> 01:11:35.005
uh, uh, need to be computed, uh,

1124
01:11:35.865 --> 01:11:38.125
uh, for, for this particular neur network?

1125
01:11:40.735 --> 01:11:44.235
Any takes given the network structure, like three inputs,

1126
01:11:44.235 --> 01:11:45.755
four hidden, and one output,

1127
01:11:46.215 --> 01:11:47.915
how many different weights and biases?

1128
01:11:48.495 --> 01:11:51.155
Uh, let's ignore the biases, even if it's the weights.

1129
01:11:51.215 --> 01:11:53.195
How many weights needs to be computed?

1130
01:11:58.995 --> 01:12:00.165
Yeah, absolutely. So,

1131
01:12:00.745 --> 01:12:03.405
so the way 16 is the right answer here.

1132
01:12:03.545 --> 01:12:07.365
So the way, uh, that is computed is

1133
01:12:08.145 --> 01:12:10.685
you have three times four weights.

1134
01:12:10.685 --> 01:12:15.525
So you have your all, uh, 12 weights through these,

1135
01:12:16.505 --> 01:12:20.425
um, connections, uh, how much they're weighted at,

1136
01:12:20.965 --> 01:12:23.025
and then you have another four weights here.

1137
01:12:24.045 --> 01:12:27.235
So, um, that is four times one.

1138
01:12:27.935 --> 01:12:29.835
Um, so, so that's how you come

1139
01:12:29.835 --> 01:12:33.795
to 16 weights without including the biases, uh,

1140
01:12:33.795 --> 01:12:34.795
in this particular case.

1141
01:12:49.335 --> 01:12:52.265
Cool. Um, let me know if you have any questions,

1142
01:12:52.325 --> 01:12:55.625
but, um, essentially that's, that's how you ca uh, you

1143
01:12:56.215 --> 01:13:00.465
calculate how many parameters are needed for a given, uh,

1144
01:13:00.465 --> 01:13:01.545
neur network structure.

1145
01:13:05.095 --> 01:13:08.515
Um, again, some examples of, um, neural networks

1146
01:13:08.515 --> 01:13:11.755
where there are multiple, uh, layers as well.

1147
01:13:12.415 --> 01:13:16.435
Uh, so in this case, in the top case, the multilayer f

1148
01:13:16.435 --> 01:13:21.235
and n has, uh, more hidden layers, uh, more than one, uh,

1149
01:13:21.375 --> 01:13:23.155
in addition to the input and output.

1150
01:13:23.815 --> 01:13:27.395
Uh, so this is your, uh, input, and this is our output.

1151
01:13:27.455 --> 01:13:30.215
And there are hidden layers here.

1152
01:13:30.755 --> 01:13:33.815
Uh, these, these have more than two here

1153
01:13:33.955 --> 01:13:34.975
in this particular case.

1154
01:13:35.755 --> 01:13:38.295
Um, and the number of hidden layers

1155
01:13:38.555 --> 01:13:40.615
and number of neurons in each layer can vary.

1156
01:13:41.155 --> 01:13:42.575
Uh, it depends on the problem

1157
01:13:43.355 --> 01:13:45.815
and the design complexity of the model.

1158
01:13:46.235 --> 01:13:47.535
So as we increase the layers

1159
01:13:47.715 --> 01:13:49.335
and the number of neurons in each layer,

1160
01:13:49.365 --> 01:13:50.895
that increases the complexity.

1161
01:13:52.495 --> 01:13:55.435
Um, and we discussed about fully connected layers in fully

1162
01:13:55.435 --> 01:13:59.195
connected, uh, layers, uh, also known as, uh,

1163
01:13:59.195 --> 01:14:00.715
dense layers or dense network.

1164
01:14:01.345 --> 01:14:04.635
Each neuron in a layer is connected to, uh,

1165
01:14:04.725 --> 01:14:06.995
every neuron in the adjacent layers.

1166
01:14:07.695 --> 01:14:10.755
Um, so, uh, we talked about this like, you know, uh,

1167
01:14:10.755 --> 01:14:12.405
like every neuron is connected

1168
01:14:12.405 --> 01:14:14.645
to every other neuron in the next layer.

1169
01:14:25.885 --> 01:14:29.185
So in this particular example, uh, can you tell me, like,

1170
01:14:29.285 --> 01:14:31.065
now we include the biases as well.

1171
01:14:31.485 --> 01:14:35.265
Can you tell me how many, uh, uh, parameters we need, uh,

1172
01:14:35.265 --> 01:14:39.785
between, uh, let's start with, uh, how many we need between

1173
01:14:40.045 --> 01:14:44.905
how many parameters we need between input

1174
01:14:46.035 --> 01:14:47.455
and H one.

1175
01:14:58.475 --> 01:14:59.635
H one is hidden layer one.

1176
01:15:15.055 --> 01:15:18.835
So, uh, so we have three nodes in input layer

1177
01:15:19.735 --> 01:15:23.475
and four nodes and, uh, hidden layer one.

1178
01:15:23.855 --> 01:15:25.155
So we need 12 weights.

1179
01:15:25.735 --> 01:15:28.435
Uh, and then we need, uh,

1180
01:15:28.665 --> 01:15:30.835
four biases, right?

1181
01:15:31.935 --> 01:15:34.875
So, so we need for between input

1182
01:15:34.935 --> 01:15:36.315
and hidden between these two.

1183
01:15:37.645 --> 01:15:40.345
We need 16 rams total.

1184
01:15:42.365 --> 01:15:46.745
Now, with the same logic, uh, how many parameters do we need

1185
01:15:47.415 --> 01:15:49.985
between hidden layer one and hidden layer two?

1186
01:16:07.885 --> 01:16:09.815
Yeah, it's the same 60.

1187
01:16:10.195 --> 01:16:13.535
Um, so I think, uh, it's flipped the other way around here.

1188
01:16:13.645 --> 01:16:16.495
Four, uh, hidden, hidden layer one.

1189
01:16:16.675 --> 01:16:20.495
So actually not 16, actually four into three.

1190
01:16:21.125 --> 01:16:25.975
There's only three biases, right? So it's actually 15.

1191
01:16:27.455 --> 01:16:32.255
Um, so, um, do you know how, how that's calculated?

1192
01:16:32.255 --> 01:16:34.055
So we only need three biases, right?

1193
01:16:34.635 --> 01:16:38.495
But these three nodes, so it's, uh, actually 15.

1194
01:16:42.945 --> 01:16:47.445
And then finally with the output layer, uh, between H two

1195
01:16:48.025 --> 01:16:52.435
and output, uh, how many do we need?

1196
01:16:57.545 --> 01:16:58.645
May? Good, good question.

1197
01:16:58.865 --> 01:17:02.815
Um, so share, uh, let me answer that. Um,

1198
01:17:11.565 --> 01:17:12.705
so far, um,

1199
01:17:16.095 --> 01:17:20.885
the output layer, uh, yeah, it's three times two plus two.

1200
01:17:21.025 --> 01:17:23.325
So we have eight, uh, parameters.

1201
01:17:23.985 --> 01:17:25.525
Um, so total, uh,

1202
01:17:25.545 --> 01:17:29.525
we have 16 plus 15 plus eight, right?

1203
01:17:29.625 --> 01:17:33.465
So 39

1204
01:17:33.675 --> 01:17:35.585
parameters in, in total.

1205
01:17:36.245 --> 01:17:39.105
Um, so even with a small network, we have like, you know,

1206
01:17:39.205 --> 01:17:43.665
uh, like this, uh, 39 parameters, uh, if you look at like,

1207
01:17:43.665 --> 01:17:46.705
you know, some of the more, uh, popular models like,

1208
01:17:46.705 --> 01:17:50.465
you know, GPT, uh, class models, uh, the number

1209
01:17:50.465 --> 01:17:54.505
of parameters is in like, uh, several millions to billions.

1210
01:17:55.005 --> 01:17:57.785
Um, so, so that's the scale we are looking at.

1211
01:17:58.285 --> 01:18:00.425
Um, there is an interesting paper, uh,

1212
01:18:00.425 --> 01:18:03.585
called Chinchilla paper, uh, where, you know, there is a

1213
01:18:04.175 --> 01:18:07.065
kind of analysis between the input size

1214
01:18:08.245 --> 01:18:10.185
and the number of parameters required

1215
01:18:10.325 --> 01:18:12.265
to learn efficiently from the input.

1216
01:18:12.845 --> 01:18:16.505
Uh, uh, that's, uh, an active area of research, like,

1217
01:18:16.505 --> 01:18:18.385
you know, how many parameters is too much,

1218
01:18:18.405 --> 01:18:21.265
how many parameters is too little to learn something.

1219
01:18:21.805 --> 01:18:24.745
Uh, so that's, uh, that's also, uh, an active area

1220
01:18:24.745 --> 01:18:26.985
of research on how, how we decide

1221
01:18:27.205 --> 01:18:30.025
how many parameters are needed, uh, for a given network.

1222
01:18:31.125 --> 01:18:33.875
Um, cool.

1223
01:18:33.935 --> 01:18:36.075
So biases is essentially, uh,

1224
01:18:36.275 --> 01:18:38.075
I think it came up in one of the questions.

1225
01:18:38.095 --> 01:18:43.035
So, so the way this calculation happens is, so let's take,

1226
01:18:43.335 --> 01:18:44.905
um, um,

1227
01:18:47.205 --> 01:18:48.775
this node as example, right?

1228
01:18:48.915 --> 01:18:52.215
So, so it has inputs coming from all of these.

1229
01:18:53.235 --> 01:18:57.885
So, so I one times w

1230
01:18:58.825 --> 01:19:01.645
one plus i, two times W2

1231
01:19:02.155 --> 01:19:05.365
plus i three times W three, uh,

1232
01:19:05.465 --> 01:19:07.605
and then you add a bio term, right?

1233
01:19:08.625 --> 01:19:11.605
Um, and then you do the activation, whatever

1234
01:19:11.605 --> 01:19:13.685
that is really, uh, oops.

1235
01:19:15.595 --> 01:19:18.055
Um, so I don't know what I did there,

1236
01:19:18.115 --> 01:19:22.575
but essentially you need a bias, uh, to, to be able to, uh,

1237
01:19:22.755 --> 01:19:26.255
add to, to that activation so that, you know, uh,

1238
01:19:26.255 --> 01:19:29.095
you can control, uh, not just the weight,

1239
01:19:29.195 --> 01:19:32.655
but also the, uh, areas where, you know, you need

1240
01:19:32.655 --> 01:19:36.655
to scale the, uh, the input, uh, to be able to learn better.

1241
01:19:42.905 --> 01:19:45.405
Uh, I think, uh, just a

1242
01:19:46.565 --> 01:19:48.025
follow up from previous slide.

1243
01:19:49.275 --> 01:19:53.455
So, alright,

1244
01:19:54.075 --> 01:19:58.495
so let's, uh, uh, quickly go through how many,

1245
01:19:58.915 --> 01:20:00.495
is there any understanding how many,

1246
01:20:00.995 --> 01:20:02.575
how we decide how many hidden layers?

1247
01:20:03.235 --> 01:20:06.495
Uh, good question. Um, I'll give you some pointers.

1248
01:20:06.635 --> 01:20:10.445
So depends on the one is,

1249
01:20:10.585 --> 01:20:12.205
it depends on the complexity of the problem.

1250
01:20:12.425 --> 01:20:16.005
So I always start with, um, two ways.

1251
01:20:16.185 --> 01:20:20.005
Uh, start with, um, you know, if you,

1252
01:20:20.345 --> 01:20:22.925
if you know the problem you're trying to solve, let's say a

1253
01:20:23.525 --> 01:20:25.085
classification from images,

1254
01:20:26.455 --> 01:20:29.155
and you probably read some literature, right?

1255
01:20:29.215 --> 01:20:33.995
So like, you know, how these, uh, um, object detection kind

1256
01:20:33.995 --> 01:20:36.195
of problem or classification problems are solved

1257
01:20:36.495 --> 01:20:38.635
and you can inspire from those architectures.

1258
01:20:38.635 --> 01:20:39.915
So that's one way, uh,

1259
01:20:39.915 --> 01:20:42.075
and you can try to, you know, mimic some

1260
01:20:42.075 --> 01:20:43.115
of those architectures.

1261
01:20:43.815 --> 01:20:46.635
Um, the other way is to, you know, uh, uh,

1262
01:20:47.015 --> 01:20:51.475
the problem is like an easy, uh, learning, like, you know,

1263
01:20:51.825 --> 01:20:54.675
cats and dogs, very easy to learn.

1264
01:20:55.175 --> 01:20:57.875
Um, and the complexity is pretty low there.

1265
01:20:58.215 --> 01:21:01.395
Uh, maybe, uh, you know, you, you're already seeing like,

1266
01:21:01.395 --> 01:21:02.955
you know, even with baseline models,

1267
01:21:02.955 --> 01:21:04.035
you're seeing high pressure.

1268
01:21:04.035 --> 01:21:06.835
So maybe you don't need a deep, uh, complex network.

1269
01:21:07.015 --> 01:21:11.195
So maybe you can start with, you know, a few layers, um, uh,

1270
01:21:11.655 --> 01:21:16.515
to learn the latent features, uh, with, uh, you know, with,

1271
01:21:16.575 --> 01:21:18.195
uh, some sort of scaling from,

1272
01:21:18.195 --> 01:21:20.675
let's say it's a pixel of a hundred by hundred.

1273
01:21:21.215 --> 01:21:25.235
So you have, uh, you know, uh, 10,000 input features.

1274
01:21:25.695 --> 01:21:29.755
Um, so you are looking at some sort of scale down to maybe,

1275
01:21:30.015 --> 01:21:32.595
uh, you know, 5,000, uh,

1276
01:21:33.475 --> 01:21:35.115
features in the hidden layer one

1277
01:21:35.335 --> 01:21:37.635
and another 5,000 hidden layer two.

1278
01:21:37.935 --> 01:21:40.875
And then you, uh, you, you're trying

1279
01:21:40.875 --> 01:21:43.875
to create a classification of, you know, output neuron.

1280
01:21:43.875 --> 01:21:46.755
So, so based on that, yeah, you'll get some intuition into,

1281
01:21:46.895 --> 01:21:48.755
you know, how many neurons in each layer,

1282
01:21:49.455 --> 01:21:50.555
uh, and so on, on forth.

1283
01:21:50.695 --> 01:21:51.875
So, so there are multiple ways.

1284
01:21:52.165 --> 01:21:57.155
There is also, uh, a active research like, you know, uh,

1285
01:21:57.555 --> 01:21:59.635
I think neural architecture set.

1286
01:22:00.255 --> 01:22:04.355
Uh, so, so there is, it's kind of trying to find

1287
01:22:04.355 --> 01:22:07.515
what is the right neural architecture for a given problem.

1288
01:22:08.455 --> 01:22:10.475
So it's kind of learning from the data,

1289
01:22:10.475 --> 01:22:12.035
what is the right neural architecture.

1290
01:22:12.655 --> 01:22:17.475
Um, so that's, that's another, uh, uh, way, uh,

1291
01:22:17.595 --> 01:22:21.315
more sophisticated way to find, uh, how to decide

1292
01:22:21.315 --> 01:22:23.675
what the neur architecture should be.

1293
01:22:24.095 --> 01:22:26.995
Uh, hopefully that answers, uh, uh,

1294
01:22:27.315 --> 01:22:30.155
I think someone asked number, I think.

1295
01:22:34.155 --> 01:22:36.685
Cool. Uh, let me know if you are in the chat.

1296
01:22:36.905 --> 01:22:39.805
We know, like, you know, if your questions, uh,

1297
01:22:39.805 --> 01:22:41.925
haven't been answered, I'm happy to follow up on those.

1298
01:22:46.125 --> 01:22:50.315
Alright, so let's go through, uh,

1299
01:22:50.695 --> 01:22:52.755
new, actually.

1300
01:22:52.775 --> 01:22:55.715
So yeah, let's go through an f, f and n example.

1301
01:22:56.575 --> 01:23:00.235
Uh, so for this, uh, we'll use a

1302
01:23:00.885 --> 01:23:03.475
digit recogni dataset.

1303
01:23:03.535 --> 01:23:07.485
Um, let's enter, introduce that dataset, uh, quickly.

1304
01:23:08.895 --> 01:23:13.595
Um, so, so these are handwritten digits, uh,

1305
01:23:13.705 --> 01:23:17.755
that are, uh, that have 28 by 28 pixels.

1306
01:23:18.375 --> 01:23:21.835
Um, so, so total 784 pixels in total.

1307
01:23:22.855 --> 01:23:26.835
Um, and each pixel has, uh, so these are gray scale.

1308
01:23:27.375 --> 01:23:29.395
So each pixel has a value between zero

1309
01:23:29.415 --> 01:23:33.635
and 2, 5, 2, 5 being the darkest and zero being white.

1310
01:23:34.455 --> 01:23:38.435
Um, so, uh, so essentially trained dataset has these

1311
01:23:39.225 --> 01:23:42.335
sound 85 columns, uh, 7 84 being the pixel values.

1312
01:23:42.835 --> 01:23:47.335
And then there is a label, uh, uh, which is the, uh,

1313
01:23:47.555 --> 01:23:49.935
the digit, uh, like if it's a seven,

1314
01:23:50.165 --> 01:23:51.895
then it's, uh, labeled as seven.

1315
01:23:53.645 --> 01:23:55.305
And, um,

1316
01:23:55.925 --> 01:23:59.505
and essentially, uh, that's, let's look at this dataset,

1317
01:23:59.645 --> 01:24:00.665
see, see how it looks.

1318
01:24:00.805 --> 01:24:03.185
Uh, it'll be more intuitive when we look at it.

1319
01:24:04.695 --> 01:24:07.235
Uh, so for this, uh, I'm using touch,

1320
01:24:08.095 --> 01:24:09.995
uh, uh, framework.

1321
01:24:10.255 --> 01:24:13.115
Uh, it's a very popular framework for developing, uh,

1322
01:24:13.305 --> 01:24:16.115
neur networks, uh, neur networks.

1323
01:24:16.815 --> 01:24:20.515
Um, likewise there is, uh, tens of flow side of things like

1324
01:24:21.215 --> 01:24:23.235
and terms of flow, which we'll also look at.

1325
01:24:23.735 --> 01:24:26.195
Um, but torch is, are very popular, uh,

1326
01:24:26.265 --> 01:24:27.755
because of its ease of use.

1327
01:24:29.795 --> 01:24:31.615
So just doing some basic imports.

1328
01:24:31.995 --> 01:24:36.725
Um, um, I'm importing the torch, uh,

1329
01:24:36.785 --> 01:24:39.685
and then package, uh, which is the Neur Network package.

1330
01:24:40.625 --> 01:24:44.005
Uh, and using s scale, learn

1331
01:24:44.025 --> 01:24:47.585
for doing basic functions like train split, uh,

1332
01:24:47.685 --> 01:24:52.185
and as you might be already aware, uh, for basic, uh,

1333
01:24:52.585 --> 01:24:56.105
handling of errors and data frames, uh,

1334
01:24:56.325 --> 01:24:59.105
and using map plot for plotting.

1335
01:25:04.845 --> 01:25:08.905
Let mount my cool drive, hopefully.

1336
01:25:09.975 --> 01:25:10.265
Oops,

1337
01:25:14.725 --> 01:25:15.075
right.

1338
01:25:15.295 --> 01:25:17.755
So I think I have it mounted.

1339
01:25:19.095 --> 01:25:22.115
Let me see where I need to change the path.

1340
01:25:31.435 --> 01:25:32.525
Alright, cool.

1341
01:25:33.635 --> 01:25:37.195
So, cloud class.

1342
01:25:39.225 --> 01:25:42.795
Okay. Looks like it. Looking good.

1343
01:25:43.135 --> 01:25:47.465
So yeah, so

1344
01:25:47.975 --> 01:25:51.825
just reading in the CSV files, uh, for train and test

1345
01:25:52.925 --> 01:25:57.705
and, um, looking at, you know, basic sanity checks for

1346
01:25:58.445 --> 01:25:59.665
the shape of the dataset.

1347
01:25:59.765 --> 01:26:03.105
So as you can see, the train dataset has one extra

1348
01:26:03.995 --> 01:26:05.695
column, uh, for the label.

1349
01:26:07.095 --> 01:26:11.115
And, uh, uh, essentially the 7 84 pixel values.

1350
01:26:12.125 --> 01:26:17.105
Uh, and then there are 42,000, uh, observations in train

1351
01:26:17.325 --> 01:26:19.545
and test has 28,000.

1352
01:26:20.285 --> 01:26:23.565
Um, so, so that's the, uh,

1353
01:26:23.765 --> 01:26:25.845
a quick look at the head of the dataset.

1354
01:26:26.025 --> 01:26:28.205
Uh, so you can see like, you know, a bunch

1355
01:26:28.225 --> 01:26:31.925
of these pixel values, um, starting from column two,

1356
01:26:31.925 --> 01:26:33.005
but there is also a label.

1357
01:26:34.025 --> 01:26:37.405
Um, so that's how the data is set up.

1358
01:26:47.305 --> 01:26:50.485
So let's do some basic, uh, understanding for,

1359
01:26:50.665 --> 01:26:51.845
you know, label counts.

1360
01:26:52.505 --> 01:26:55.945
Um, so as you can see, they're fairly

1361
01:26:56.575 --> 01:27:00.305
equally distributed, uh, in the trained data, uh,

1362
01:27:00.365 --> 01:27:03.665
around 4,000 per each, uh, label.

1363
01:27:03.685 --> 01:27:06.425
So you have 10 digits, uh, zero to nine.

1364
01:27:07.285 --> 01:27:12.065
Uh, and, um, yeah, they are fairly equally distributed.

1365
01:27:12.245 --> 01:27:16.025
So, uh, there are no, uh, edge cases

1366
01:27:16.325 --> 01:27:19.265
or, you know, sparse labels for certain categories.

1367
01:27:22.655 --> 01:27:26.785
Uh, doing some basic conversion here, um, like, you know,

1368
01:27:26.925 --> 01:27:30.955
um, um, converting to MPA array

1369
01:27:31.175 --> 01:27:35.475
or, you know, to be able to, uh, use it for our, uh, models.

1370
01:27:36.655 --> 01:27:40.835
Um, and then setting the label, um, properly.

1371
01:27:42.225 --> 01:27:44.325
Um, let's visualize some of these images,

1372
01:27:44.425 --> 01:27:47.725
how they look like, uh, like, um, essentially I'm

1373
01:27:48.365 --> 01:27:53.285
plotting the, uh, each pixel value of the image here by

1374
01:27:54.035 --> 01:27:57.285
reshaping it back to 28 by 28, uh, instead

1375
01:27:57.285 --> 01:27:58.765
of the flat and 7 84.

1376
01:27:59.745 --> 01:28:04.085
Um, so, so, yeah,

1377
01:28:04.545 --> 01:28:08.165
so these are, this is how the handwritten digits look like.

1378
01:28:08.945 --> 01:28:11.205
Um, uh, it's showing in color here,

1379
01:28:11.205 --> 01:28:12.445
but these are all gray scale.

1380
01:28:14.295 --> 01:28:18.115
Um, so, uh, as you can see, like some of the digits, like,

1381
01:28:18.135 --> 01:28:21.955
you know, 1 0 4, um, the,

1382
01:28:22.015 --> 01:28:23.515
and the labels associated with them.

1383
01:28:24.175 --> 01:28:28.305
Uh, here, um, I want to quickly check,

1384
01:28:28.485 --> 01:28:32.895
is the zoom okay, on the, on the coding notebook?

1385
01:28:32.955 --> 01:28:36.095
Uh, sometimes the code can show up as pretty small.

1386
01:28:37.235 --> 01:28:40.655
Uh, just want to check, uh, is the zooming, okay.

1387
01:28:43.945 --> 01:28:44.235
Okay.

1388
01:28:50.485 --> 01:28:54.745
Um, so again, uh, now, now

1389
01:28:54.745 --> 01:28:58.305
that we have the train side, let's split that.

1390
01:28:58.405 --> 01:29:00.145
Uh, so that's the train file.

1391
01:29:00.605 --> 01:29:02.725
Uh, we'll split that into, uh,

1392
01:29:02.825 --> 01:29:04.205
you know, training and validation.

1393
01:29:04.825 --> 01:29:08.085
Um, just, uh, what's a good rule of thumb?

1394
01:29:08.155 --> 01:29:12.285
Like, you know, um, for splitting between training

1395
01:29:12.285 --> 01:29:14.525
and validation, what's a good percentage?

1396
01:29:30.065 --> 01:29:34.625
Yeah, Uh,

1397
01:29:34.905 --> 01:29:36.585
I think fairly good answers here.

1398
01:29:36.855 --> 01:29:40.105
Like, you know, um, 60, 20, 20, like, I think

1399
01:29:40.105 --> 01:29:42.625
that's train te train validation test.

1400
01:29:43.365 --> 01:29:46.465
Um, 70 to 80% for training

1401
01:29:46.645 --> 01:29:51.465
and remaining 20% for, um, validation.

1402
01:29:52.065 --> 01:29:53.785
I think, uh, that's, those are fair.

1403
01:29:54.325 --> 01:29:56.665
Um, any, any takers like, you know, um,

1404
01:29:57.205 --> 01:29:58.705
why we need a test set?

1405
01:29:58.885 --> 01:30:03.105
Uh, just curious, uh, if we have validation, uh, why,

1406
01:30:03.125 --> 01:30:04.265
why do we need a test set?

1407
01:30:21.725 --> 01:30:23.695
Yeah. Um, fair enough.

1408
01:30:23.715 --> 01:30:28.315
But, um, inval, they're essentially not

1409
01:30:28.875 --> 01:30:30.155
training on the validation data.

1410
01:30:30.255 --> 01:30:31.835
So curious, uh, why, why,

1411
01:30:31.895 --> 01:30:33.955
why do we need an another test set?

1412
01:30:49.525 --> 01:30:52.575
Yeah, so, um, essentially, uh,

1413
01:30:52.795 --> 01:30:56.375
during the train validation testing phases, uh,

1414
01:30:58.405 --> 01:31:00.065
uh, right

1415
01:31:00.245 --> 01:31:02.925
before running, yeah, so,

1416
01:31:03.265 --> 01:31:05.245
so you're still using validation data

1417
01:31:05.425 --> 01:31:06.805
to a certain fashion, right?

1418
01:31:06.945 --> 01:31:11.725
To inform your decisions, what to stop it, um, how

1419
01:31:11.825 --> 01:31:14.725
to, where to stop in terms of, you know,

1420
01:31:14.745 --> 01:31:15.765
the last convergence.

1421
01:31:16.385 --> 01:31:20.885
Uh, or, uh, sometimes even with cross validation,

1422
01:31:20.905 --> 01:31:23.005
you are seeing some parts of validation data.

1423
01:31:23.705 --> 01:31:27.845
So there is some leakage, uh, not even if it's not

1424
01:31:27.845 --> 01:31:29.085
through direct data,

1425
01:31:29.345 --> 01:31:30.965
but there is some indirect leakage

1426
01:31:30.965 --> 01:31:32.285
between validation and training.

1427
01:31:33.295 --> 01:31:35.795
The intuition behind having a separate asset is to

1428
01:31:36.765 --> 01:31:41.555
completely separate, uh, uh, the dataset from all of that.

1429
01:31:42.255 --> 01:31:45.915
Uh, typically, uh, in real world, like, you know, um,

1430
01:31:47.175 --> 01:31:51.635
uh, use, uh, uh, let's say if you're using some sort of,

1431
01:31:51.655 --> 01:31:54.355
you know, stock market prediction,

1432
01:31:54.355 --> 01:31:58.675
so typically you use like validation data from like,

1433
01:31:59.435 --> 01:32:01.005
it's, uh, future time.

1434
01:32:01.155 --> 01:32:03.605
Like if train and test is like 2023,

1435
01:32:03.775 --> 01:32:05.725
train validation is 2023.

1436
01:32:06.385 --> 01:32:11.285
You use, uh, test dataset from 2024, uh, to see

1437
01:32:11.285 --> 01:32:12.965
how, you know, that's how it works, right?

1438
01:32:13.145 --> 01:32:15.285
You in real world, like you build a model today

1439
01:32:15.285 --> 01:32:17.245
and you apply it to future data.

1440
01:32:17.905 --> 01:32:21.645
So, uh, so that's how you kind of separate, uh, completely,

1441
01:32:21.905 --> 01:32:23.085
uh, test dataset.

1442
01:32:23.665 --> 01:32:25.685
Um, and, uh, validation

1443
01:32:25.685 --> 01:32:27.925
and training are typically from similar timeframes,

1444
01:32:28.425 --> 01:32:30.005
but, uh, test is like, you know,

1445
01:32:30.305 --> 01:32:31.685
is mostly a future timeframe.

1446
01:32:32.575 --> 01:32:33.465
Well separated

1447
01:32:33.465 --> 01:32:38.465
temporarily

1448
01:32:38.925 --> 01:32:43.145
Now that we've seen the dataset, how it looks like, um, um,

1449
01:32:43.435 --> 01:32:46.025
let's also split, uh, this dataset.

1450
01:32:46.025 --> 01:32:50.105
And here we're using a split size of, you know, 80 20.

1451
01:32:50.925 --> 01:32:55.855
Um, so, so we'll split the initial 40

1452
01:32:55.855 --> 01:32:59.335
2K across these, um, 33 k

1453
01:32:59.395 --> 01:33:01.175
and eight 8,400.

1454
01:33:02.545 --> 01:33:05.445
Uh, also check, you know, quick sanity check, uh,

1455
01:33:05.455 --> 01:33:07.365
after that should be like, you know,

1456
01:33:07.465 --> 01:33:10.005
are both these datasets equally distributed?

1457
01:33:10.745 --> 01:33:13.715
Um, so, uh, again, looking at the same

1458
01:33:14.375 --> 01:33:18.555
bar charts across these, uh, so looks fairly similar to me.

1459
01:33:18.775 --> 01:33:20.905
Um, so no issues there.

1460
01:33:21.715 --> 01:33:23.595
Um, and,

1461
01:33:24.375 --> 01:33:28.995
and then, uh, we'll use, uh, the AYA

1462
01:33:29.295 --> 01:33:31.795
to tensor, uh, to, uh,

1463
01:33:31.975 --> 01:33:34.715
before, uh, uh, training the model.

1464
01:33:35.455 --> 01:33:38.555
So tensor is essentially think of like, you know, like, uh,

1465
01:33:39.035 --> 01:33:41.355
a multidimensional, uh, matrix.

1466
01:33:42.175 --> 01:33:45.975
Uh, so, you know, scaler,

1467
01:33:46.075 --> 01:33:47.215
vector matrix

1468
01:33:48.115 --> 01:33:51.655
and tensor is like a multidimensional, uh, matrix,

1469
01:33:51.925 --> 01:33:54.415
essentially, uh, nothing more than that.

1470
01:33:57.805 --> 01:34:00.905
So, and we're, we're using touch function

1471
01:34:01.365 --> 01:34:04.105
to the flow tensor for that particular use case.

1472
01:34:04.205 --> 01:34:07.505
Uh, for this particular, uh, since, you know, we have, uh,

1473
01:34:07.805 --> 01:34:11.625
values between 0 2 5, uh, even though I think we are good

1474
01:34:11.625 --> 01:34:14.065
with into values, we're using flow tens here,

1475
01:34:14.975 --> 01:34:17.675
and I'll tell you why we are using actually, uh,

1476
01:34:17.695 --> 01:34:18.835
and there is, I think, uh,

1477
01:34:18.835 --> 01:34:20.835
we're doing some normalization later on.

1478
01:34:21.675 --> 01:34:25.655
Um, so next thing is to, uh, define the model.

1479
01:34:26.155 --> 01:34:30.775
Uh, so for this, um, we'll use the, uh, touch

1480
01:34:30.875 --> 01:34:32.215
and in model, uh, module.

1481
01:34:32.875 --> 01:34:36.535
Uh, from that, uh, we'll use the, the different layers.

1482
01:34:36.795 --> 01:34:40.895
In this case, we are using the linear layers, which are, uh,

1483
01:34:41.125 --> 01:34:42.135
densely connected.

1484
01:34:42.875 --> 01:34:47.605
So here we are using, uh, four layers, uh,

1485
01:34:48.065 --> 01:34:52.205
and they're named as FC one, FC two, FC three, FC four, uh,

1486
01:34:52.345 --> 01:34:56.485
and as you can see, FC one is the, uh, the number

1487
01:34:56.485 --> 01:35:01.125
of input features is same as the number of pixels, 10 84.

1488
01:35:01.955 --> 01:35:06.495
And the output features here we are scaling down, um, uh,

1489
01:35:06.715 --> 01:35:10.495
if you remember me telling, like, you know, how to decide

1490
01:35:10.515 --> 01:35:13.735
how many, um, nodes in the head

1491
01:35:13.735 --> 01:35:16.255
and layer, so kind of, you know, kind of take the input

1492
01:35:16.435 --> 01:35:18.455
and kind of scale down gradually

1493
01:35:18.835 --> 01:35:20.735
to reach the final set here.

1494
01:35:20.755 --> 01:35:24.415
So here we are scaling down to 600, uh, in the first layer

1495
01:35:24.515 --> 01:35:28.015
to 500 in the second layer to two 50 in the third layer,

1496
01:35:28.555 --> 01:35:32.175
and then finally to 10, uh, and 10,

1497
01:35:32.175 --> 01:35:33.815
because we, we have 10 classes.

1498
01:35:34.675 --> 01:35:37.935
Uh, so that's how we go from 7 84 pixels

1499
01:35:37.955 --> 01:35:40.495
to finally 10, uh, classes.

1500
01:35:42.805 --> 01:35:47.745
Uh, and then, uh, um, we are using, uh, uh,

1501
01:35:48.125 --> 01:35:49.705
as you can see from here, uh, what kind

1502
01:35:49.705 --> 01:35:51.105
of activation function are we using?

1503
01:36:02.805 --> 01:36:05.065
Uh, we are using a relu activation function.

1504
01:36:05.165 --> 01:36:08.865
Uh, can someone tell me what is the output, uh, range

1505
01:36:09.005 --> 01:36:10.825
for relu activation function?

1506
01:36:22.865 --> 01:36:25.515
Yeah, zero two plus two infinity. Yeah.

1507
01:36:26.335 --> 01:36:27.395
Uh, Vincent, um,

1508
01:36:28.255 --> 01:36:32.315
and, um, let's see.

1509
01:36:37.475 --> 01:36:41.245
Yeah, cool. So essentially, uh, yeah, we have four layers,

1510
01:36:41.545 --> 01:36:44.925
uh, downsampling, uh, gradually across these layers.

1511
01:36:45.985 --> 01:36:50.525
And, uh, so if you ask me why four layers versus maybe can

1512
01:36:50.525 --> 01:36:51.845
we do this with three, we can experiment,

1513
01:36:52.265 --> 01:36:56.365
but, uh, uh, I think this is, uh, um,

1514
01:36:57.155 --> 01:37:00.605
this network structure is, uh, I think, uh,

1515
01:37:01.275 --> 01:37:02.765
several instructors

1516
01:37:02.765 --> 01:37:04.765
before we played around this network structure

1517
01:37:04.945 --> 01:37:07.005
and came up with this architecture.

1518
01:37:07.585 --> 01:37:10.125
Uh, but, um, you guys should play

1519
01:37:10.125 --> 01:37:11.285
around like, uh, see what happens.

1520
01:37:11.355 --> 01:37:13.805
Like, you know, what the accuracy levels are.

1521
01:37:14.185 --> 01:37:17.205
Uh, you use like, you know, uh, just two layers,

1522
01:37:17.505 --> 01:37:18.565
uh, versus three layers.

1523
01:37:19.225 --> 01:37:23.565
Uh, it's always, uh, you know, find the best

1524
01:37:24.685 --> 01:37:26.685
smallest network possible to solve your problem.

1525
01:37:27.345 --> 01:37:29.365
Uh, the more simpler, the better, obviously.

1526
01:37:29.945 --> 01:37:34.245
Um, so, um, so something you can experiment a little bit.

1527
01:37:40.725 --> 01:37:43.625
Um, so, uh, another quick thing I want to point out.

1528
01:37:43.645 --> 01:37:46.265
As you can see, even with this small network,

1529
01:37:46.655 --> 01:37:50.265
like your number of parameters are kind of explosive.

1530
01:37:50.265 --> 01:37:51.585
Like, you know, if you're looking at,

1531
01:37:51.585 --> 01:37:54.185
like in previous calculations, um,

1532
01:37:54.325 --> 01:37:56.925
so you're looking at 7 84 times

1533
01:37:57.785 --> 01:37:59.405
600 plus 600.

1534
01:37:59.405 --> 01:38:02.685
That's, that's a big number, uh, like even with, you know,

1535
01:38:02.685 --> 01:38:03.685
with this architecture.

1536
01:38:04.225 --> 01:38:08.445
Um, so, so, so that's, uh, that's the impact of, you know,

1537
01:38:08.665 --> 01:38:10.205
the number of layers

1538
01:38:10.385 --> 01:38:13.325
and, uh, number of neurons in the layer on the number

1539
01:38:13.325 --> 01:38:15.245
of parameters that the network need to learn.

1540
01:38:27.685 --> 01:38:31.135
Alright, just defining some accuracy function here, uh, so

1541
01:38:31.135 --> 01:38:33.495
that, you know, we can evaluate this

1542
01:38:34.145 --> 01:38:35.975
model once we get it going.

1543
01:38:36.515 --> 01:38:38.775
Um, how to define that, um,

1544
01:38:39.615 --> 01:38:41.295
accuracy function, what correct means.

1545
01:38:41.915 --> 01:38:46.575
Uh, it's just comparing the predicted to true label and, uh,

1546
01:38:47.435 --> 01:38:50.855
and then, uh, using an accuracy, uh, function.

1547
01:38:55.995 --> 01:38:57.885
Alright, so we define the,

1548
01:38:58.225 --> 01:39:00.445
the network architecture earlier here.

1549
01:39:00.745 --> 01:39:02.605
Uh, we just define the class,

1550
01:39:03.265 --> 01:39:07.165
and then now we'll define how to, uh, do the training.

1551
01:39:07.345 --> 01:39:09.565
Uh, we'll define a training, um, method.

1552
01:39:10.305 --> 01:39:13.805
So for that, uh, we need, uh, a data loader.

1553
01:39:14.465 --> 01:39:17.445
The number of, we need to train for, uh,

1554
01:39:17.465 --> 01:39:20.165
the model we are using, the, the model definition from,

1555
01:39:20.275 --> 01:39:22.525
from, and, um,

1556
01:39:24.065 --> 01:39:26.605
what's the stopping criteria and optimizer.

1557
01:39:27.105 --> 01:39:30.195
So these are all the things we'll, uh, define here.

1558
01:39:32.135 --> 01:39:34.185
Um, so, um,

1559
01:39:39.485 --> 01:39:40.185
let me run this.

1560
01:39:42.725 --> 01:39:44.785
Um, so, and again, we are also printing a bunch

1561
01:39:44.785 --> 01:39:48.065
of stuff at each epoch, like, you know, uh,

1562
01:39:48.215 --> 01:39:50.465
what is the, uh, training loss?

1563
01:39:50.535 --> 01:39:52.025
What is the training accuracy?

1564
01:39:52.025 --> 01:39:55.225
What is the we are at, uh, so that we can monitor

1565
01:39:55.645 --> 01:39:59.425
how the loss gets, um, um, uh, you know,

1566
01:39:59.575 --> 01:40:01.625
optimized over the iterations.

1567
01:40:02.835 --> 01:40:03.055
Um,

1568
01:40:08.015 --> 01:40:10.435
uh, and we'll talk a little bit about what data loader is.

1569
01:40:11.255 --> 01:40:14.675
Um, uh, this is a very specific method.

1570
01:40:15.135 --> 01:40:17.155
Uh, we are using to load data

1571
01:40:17.335 --> 01:40:19.515
as batches in this particular use case.

1572
01:40:27.805 --> 01:40:30.705
Um, this is an, uh, an interesting one.

1573
01:40:30.765 --> 01:40:33.105
So we are using a torch manual seed here.

1574
01:40:33.845 --> 01:40:37.955
Um, so every time you take a data set

1575
01:40:37.975 --> 01:40:41.045
and run the models, um,

1576
01:40:41.385 --> 01:40:45.805
and essentially the models, uh, the way arrays

1577
01:40:45.805 --> 01:40:49.525
and sensors work is your data is loaded in a random manner,

1578
01:40:50.145 --> 01:40:51.725
uh, not sequential all the time.

1579
01:40:52.345 --> 01:40:56.325
So the results slightly vary, uh,

1580
01:40:56.545 --> 01:40:58.005
across different runs.

1581
01:40:58.225 --> 01:41:01.725
So if you see a run with the same exact parameters,

1582
01:41:01.725 --> 01:41:06.565
which here run with, you know, 0.0, uh, uh, sorry, 90,

1583
01:41:06.585 --> 01:41:10.085
90% accuracy, the next run could be slightly different

1584
01:41:10.155 --> 01:41:12.565
with 90.1% accuracy.

1585
01:41:13.065 --> 01:41:16.045
So, but, um, if you want to remove that variability,

1586
01:41:16.475 --> 01:41:18.005
it's good to set a seed.

1587
01:41:18.895 --> 01:41:22.155
Uh, and seed is how, you know, it always goes back

1588
01:41:22.175 --> 01:41:24.355
to the right, uh, observation.

1589
01:41:24.375 --> 01:41:25.795
And then, uh,

1590
01:41:26.175 --> 01:41:31.075
and then it, uh, kind of think of it as, you know, I want

1591
01:41:31.075 --> 01:41:33.235
to replicate and reproduce the same result

1592
01:41:33.695 --> 01:41:35.755
by supplying the data set in the same way.

1593
01:41:36.495 --> 01:41:38.395
Uh, so that's, so that's when you set the seed.

1594
01:41:40.085 --> 01:41:41.865
Uh, and then in this case,

1595
01:41:41.885 --> 01:41:44.505
we are using a batch size of 1 28.

1596
01:41:44.505 --> 01:41:46.025
So we are not supplying all the

1597
01:41:46.025 --> 01:41:48.225
34,000 training data at once.

1598
01:41:48.325 --> 01:41:52.305
We are using mini batches here of each of 1 28.

1599
01:41:53.275 --> 01:41:57.435
Um, and yeah, so for the loader,

1600
01:41:57.775 --> 01:42:01.795
as I said earlier, we are using the, uh, toch, uh,

1601
01:42:01.795 --> 01:42:03.875
utility function data loader, uh,

1602
01:42:03.875 --> 01:42:05.995
with the batch size of 1 28.

1603
01:42:06.695 --> 01:42:10.675
So essentially it takes the 1 28 batch from the training

1604
01:42:10.785 --> 01:42:14.955
dataset, shuffles, and then takes under batch shuffles

1605
01:42:15.095 --> 01:42:16.875
and goes, so on and so forth.

1606
01:42:17.615 --> 01:42:19.275
Uh, and once it goes

1607
01:42:19.275 --> 01:42:21.795
through all the training data, that's one epoch.

1608
01:42:22.455 --> 01:42:26.955
Um, and, uh, we are essentially doing, running this

1609
01:42:26.955 --> 01:42:28.275
for tab 10 box.

1610
01:42:29.225 --> 01:42:31.485
You can run it for more, uh, uh,

1611
01:42:31.585 --> 01:42:33.485
but, uh, that's essentially what we're doing.

1612
01:42:34.505 --> 01:42:37.875
And, um, um, yeah,

1613
01:42:37.975 --> 01:42:40.035
so this is a multi-class problem, right?

1614
01:42:40.575 --> 01:42:43.115
Uh, so what kind of loss function would you use,

1615
01:42:43.335 --> 01:42:44.475
uh, in this particular case?

1616
01:42:58.785 --> 01:43:03.125
So, softmax is a layer, uh, you would use to, um,

1617
01:43:03.985 --> 01:43:07.725
is a kind of activation essentially you would use to, um,

1618
01:43:08.745 --> 01:43:11.445
create, um, the probabilities.

1619
01:43:11.945 --> 01:43:14.245
But in terms of loss that you would use, like

1620
01:43:14.385 --> 01:43:17.085
how would you compare, uh, the true

1621
01:43:17.345 --> 01:43:19.685
to predicted in a multi-class problem?

1622
01:43:32.405 --> 01:43:34.855
Cool. Yeah. Uh, that's, uh, uh, that's correct.

1623
01:43:35.035 --> 01:43:36.095
Uh, cross entropy.

1624
01:43:36.275 --> 01:43:41.175
Uh, so, uh, we are setting that here, uh, for the criteria,

1625
01:43:41.705 --> 01:43:42.735
cross entropy loss.

1626
01:43:43.515 --> 01:43:48.415
Uh, and then we are using Adam Optimizer, uh, which,

1627
01:43:48.415 --> 01:43:50.175
which is a very famous optimizer.

1628
01:43:50.235 --> 01:43:54.605
Um, uh, it's essentially a combination of,

1629
01:43:55.425 --> 01:43:59.765
um, AdaGrad and RMS prep, uh, kind of optimizers.

1630
01:44:00.465 --> 01:44:04.245
Um, you can, you can do some reading on, on them, um, uh,

1631
01:44:04.305 --> 01:44:05.725
and what they do especially.

1632
01:44:07.565 --> 01:44:11.335
Um, and

1633
01:44:11.535 --> 01:44:12.775
then, let's see.

1634
01:44:12.875 --> 01:44:17.175
Um, we're essentially computing the training IES losses

1635
01:44:18.195 --> 01:44:20.695
for each epoch and so on and so forth.

1636
01:44:20.795 --> 01:44:25.555
So let's, uh, start running this, uh, actually,

1637
01:44:40.275 --> 01:44:42.525
okay, so looks like there is

1638
01:44:42.675 --> 01:44:46.015
some here.

1639
01:44:46.775 --> 01:44:48.095
I probably didn't run this.

1640
01:44:51.335 --> 01:44:52.905
Alright. Um,

1641
01:44:57.125 --> 01:45:01.175
so let's see what the output shows.

1642
01:45:01.445 --> 01:45:03.615
Like, you know, for each output, for each,

1643
01:45:04.395 --> 01:45:08.015
we are emitting the training loss and the training accuracy.

1644
01:45:08.795 --> 01:45:12.375
Uh, huge drop in epoch two, uh,

1645
01:45:12.685 --> 01:45:15.255
from 91% to 97%,

1646
01:45:16.155 --> 01:45:18.975
and a huge drop in loss as well.

1647
01:45:19.395 --> 01:45:22.175
Uh, so, so training wise, you know,

1648
01:45:22.365 --> 01:45:23.535
it's going in the right direction.

1649
01:45:24.735 --> 01:45:28.835
In the next, uh, uh, labs, we'll look at like, you know,

1650
01:45:29.625 --> 01:45:31.715
what is a good criteria to stop

1651
01:45:31.855 --> 01:45:35.875
and stuff like that, uh, uh, learning rate, any ation how

1652
01:45:35.875 --> 01:45:38.195
to change the learning rate if the training is not

1653
01:45:38.665 --> 01:45:39.675
occurring properly.

1654
01:45:40.375 --> 01:45:43.195
Uh, but, uh, for this one, we'll, we'll just do the basic,

1655
01:45:43.335 --> 01:45:46.155
uh, we'll just stop based on our criteria.

1656
01:45:46.245 --> 01:45:49.395
We'll just run it till epoch 10 and stop it.

1657
01:45:56.505 --> 01:45:59.115
Okay, cool. So, looks like it's, it's a,

1658
01:45:59.185 --> 01:46:01.715
it's not a very complex, uh, problem.

1659
01:46:02.015 --> 01:46:04.755
Uh, so we, within, even within 10 ocs

1660
01:46:04.755 --> 01:46:08.385
and, you know, training data set of 33 k

1661
01:46:09.045 --> 01:46:11.905
and a small network architecture, we are able

1662
01:46:11.905 --> 01:46:14.305
to achieve like 99.3 accuracy here.

1663
01:46:15.005 --> 01:46:19.425
Um, so let's look at how, you know, uh, how to, uh,

1664
01:46:19.615 --> 01:46:20.825
this visualizes

1665
01:46:21.005 --> 01:46:24.345
and across iterations, uh, the same thing we looked at here,

1666
01:46:24.605 --> 01:46:27.985
but, uh, you know, uh, just visualizing, um,

1667
01:46:28.325 --> 01:46:32.355
and the looks like, you know, from a training standpoint,

1668
01:46:32.355 --> 01:46:33.515
it looks like everything is good.

1669
01:46:33.815 --> 01:46:35.395
Uh, what is the logical next step?

1670
01:46:35.555 --> 01:46:38.875
I mean, uh, now that you've trained the model, uh, how,

1671
01:46:38.975 --> 01:46:40.595
how do you, what do you do next?

1672
01:46:48.595 --> 01:46:51.405
Yeah, before testing, uh, maybe, uh, also, yeah,

1673
01:46:51.525 --> 01:46:53.845
I think maybe by test you are also saying validation.

1674
01:46:53.905 --> 01:46:56.325
So let's see how this does on validation.

1675
01:46:57.025 --> 01:47:01.935
Um, so we'll look at, you know, validation

1676
01:47:02.765 --> 01:47:04.535
dataset and how the predictions look

1677
01:47:04.535 --> 01:47:05.615
on the validation dataset.

1678
01:47:06.635 --> 01:47:10.455
Um, so first thing is we are doing a confusion matrix.

1679
01:47:11.435 --> 01:47:14.295
Uh, so essentially you have your predicted

1680
01:47:14.835 --> 01:47:18.695
and true values, uh, as rows and columns.

1681
01:47:19.435 --> 01:47:20.535
And essentially you want

1682
01:47:20.535 --> 01:47:23.215
to see most values being populated across the diagonal

1683
01:47:23.945 --> 01:47:27.165
and less values on, on the non diagonal numbers.

1684
01:47:27.825 --> 01:47:30.485
Uh, but you can see like some numbers where, you know,

1685
01:47:30.485 --> 01:47:34.805
there is like, you know, 30 here, 19 here, uh,

1686
01:47:35.255 --> 01:47:37.205
bunch of stuff like that, uh,

1687
01:47:37.215 --> 01:47:39.405
where these are all misclassification.

1688
01:47:40.765 --> 01:47:44.845
So, uh, those are some things that, uh, we need to,

1689
01:47:45.745 --> 01:47:47.165
uh, take care of.

1690
01:47:47.385 --> 01:47:51.325
Uh, we, these are good to investigate for that, like,

1691
01:47:51.325 --> 01:47:53.645
you know, where is the model mis mis predicting

1692
01:47:53.745 --> 01:47:55.485
misclassification, and

1693
01:47:55.635 --> 01:47:57.525
what can we do about that and stuff like that.

1694
01:47:58.145 --> 01:48:01.885
Um, so, um,

1695
01:48:04.005 --> 01:48:07.535
yeah, so in the,

1696
01:48:07.835 --> 01:48:10.975
in the way this network is set up, like if you go back,

1697
01:48:11.965 --> 01:48:16.185
so here, uh, the final layer is also linear, uh,

1698
01:48:16.485 --> 01:48:18.865
and, uh, uh,

1699
01:48:18.965 --> 01:48:21.305
so you're not essentially doing a soft max here.

1700
01:48:21.925 --> 01:48:25.705
Uh, so the output is, is, is in the form of a,

1701
01:48:26.975 --> 01:48:28.195
um, a logic.

1702
01:48:29.015 --> 01:48:30.995
Uh, so what is the, uh,

1703
01:48:33.505 --> 01:48:34.775
range of that output?

1704
01:48:40.895 --> 01:48:43.345
It's, it's, it's not in a property fashion,

1705
01:48:43.345 --> 01:48:46.385
because it's not, we didn't apply any soft max function.

1706
01:48:47.605 --> 01:48:51.485
So let's look at it. I mean, uh, we can visualize.

1707
01:48:52.865 --> 01:48:56.645
So, so this is how the, the output is like, you know,

1708
01:48:56.745 --> 01:48:59.845
now if you put that into a soft max, uh,

1709
01:48:59.915 --> 01:49:01.325
then you can get predictions.

1710
01:49:01.585 --> 01:49:05.005
Um, but essentially we use them directly here.

1711
01:49:05.025 --> 01:49:06.325
We just took the max of it

1712
01:49:06.745 --> 01:49:09.805
and then, uh, use that as our class prediction.

1713
01:49:10.265 --> 01:49:12.085
So here, we just took the max of this.

1714
01:49:12.245 --> 01:49:14.405
I think in this case, it's, uh, you know, the,

1715
01:49:14.585 --> 01:49:17.405
for this observation, the prediction is nine, uh,

1716
01:49:17.425 --> 01:49:19.605
or eight, uh, uh, actually.

1717
01:49:20.345 --> 01:49:24.965
Um, so, so essentially, yeah, you can directly use logics

1718
01:49:24.985 --> 01:49:28.125
and can, but, you know, doing a soft max on

1719
01:49:28.125 --> 01:49:30.085
that would have been nicer, um,

1720
01:49:30.085 --> 01:49:34.565
because that way you can see these as probabilities, uh,

1721
01:49:34.585 --> 01:49:38.725
rather than, um, you know, just logic, uh, values

1722
01:49:38.725 --> 01:49:39.885
that don't make any sense.

1723
01:49:43.195 --> 01:49:47.485
So here are some predictions, uh, like, you know, where, uh,

1724
01:49:47.945 --> 01:49:51.845
we predicted, uh, uh, like, uh,

1725
01:49:53.265 --> 01:49:55.765
the pre prediction versus what's actually there.

1726
01:49:56.385 --> 01:49:59.445
So most of these, uh, are, are correct.

1727
01:49:59.905 --> 01:50:01.965
Uh, you see some instance, like in this particular case,

1728
01:50:01.965 --> 01:50:03.845
we predicted eight, uh,

1729
01:50:03.845 --> 01:50:06.325
but this looks like, I don't know, a seven or two.

1730
01:50:07.325 --> 01:50:12.015
Um, so, and here it's, uh, one,

1731
01:50:12.155 --> 01:50:14.015
and prediction says four.

1732
01:50:14.835 --> 01:50:16.775
Um, so we can also look at like, you know,

1733
01:50:16.775 --> 01:50:17.895
where the prediction

1734
01:50:18.115 --> 01:50:22.495
and the, uh, label are not matching more closely.

1735
01:50:23.545 --> 01:50:27.695
Um, so yeah, you can see some instances

1736
01:50:27.785 --> 01:50:31.295
where it's misclassified, uh, like, you know,

1737
01:50:31.365 --> 01:50:34.895
this looks like, you know, uh, some noise there, like,

1738
01:50:34.895 --> 01:50:38.055
you know, it's not well written, uh, stuff like that.

1739
01:50:38.555 --> 01:50:41.815
So, again, ways to, you know, you can go deeper

1740
01:50:42.195 --> 01:50:45.255
and see what's going on with the dataset, what,

1741
01:50:45.315 --> 01:50:47.255
so why are mis predictions happening?

1742
01:50:47.875 --> 01:50:50.055
Um, so that's essentially what we're doing.

1743
01:50:54.605 --> 01:50:59.345
And then, um, um, just, uh,

1744
01:51:00.165 --> 01:51:01.505
saving the, the model

1745
01:51:02.325 --> 01:51:05.505
and, um, um,

1746
01:51:12.595 --> 01:51:17.055
um, predicting on the test dataset, uh, essentially, um,

1747
01:51:22.295 --> 01:51:24.715
so for test dataset, we don't have, uh, labeled,

1748
01:51:25.095 --> 01:51:28.155
so we'll just rely on visual inspection here.

1749
01:51:28.975 --> 01:51:32.945
Um, so again, quick visually, like, you know,

1750
01:51:33.765 --> 01:51:36.785
um, how, how we did with predictions on that test dataset.

1751
01:51:39.025 --> 01:51:40.125
And, uh, yeah.

1752
01:51:40.385 --> 01:51:44.005
Um, so that's the end of the, the coding workbook.

1753
01:51:44.625 --> 01:51:47.365
Um, so we essentially looked at, you know, how

1754
01:51:47.365 --> 01:51:49.045
to set up the using torch and,

1755
01:51:49.045 --> 01:51:51.725
and framework, uh, how to set up the layers.

1756
01:51:52.585 --> 01:51:55.485
Uh, and then, uh, once we set up the layers,

1757
01:51:55.625 --> 01:51:58.845
how do we set up the forward paths, uh, uh,

1758
01:51:59.185 --> 01:52:01.245
and what the right kind of activations are.

1759
01:52:01.945 --> 01:52:05.325
Uh, and then, uh, we looked at, you know, how

1760
01:52:05.325 --> 01:52:09.885
to set up a training function, uh, with, you know, uh,

1761
01:52:10.735 --> 01:52:12.405
batch sizes, data loader,

1762
01:52:13.145 --> 01:52:16.165
and, uh, stop, uh, criteria to stop,

1763
01:52:16.165 --> 01:52:20.685
which is the number box here, uh, looked at, uh, how

1764
01:52:20.685 --> 01:52:22.005
to set up the optimizer

1765
01:52:23.625 --> 01:52:27.045
and, uh, you know, how to emit accuracy

1766
01:52:27.045 --> 01:52:29.005
and loss across each of the training steps.

1767
01:52:30.145 --> 01:52:33.445
Um, so, so that's, um, you know, uh,

1768
01:52:34.355 --> 01:52:36.205
I'll pause there, uh, uh,

1769
01:52:36.205 --> 01:52:37.725
if you have any questions, happy to answer.

1770
01:52:58.875 --> 01:53:03.485
Cool. So, um, the next part of the class is,

1771
01:53:03.605 --> 01:53:06.725
I know, um, quick check here.

1772
01:53:07.445 --> 01:53:08.805
I saw this class to,

1773
01:53:13.175 --> 01:53:17.755
uh, we can, uh, uh, Ram, uh, it's, uh, essentially,

1774
01:53:18.015 --> 01:53:20.635
uh, uh, just wanted to show

1775
01:53:20.635 --> 01:53:22.795
that we can directly also use Logics.

1776
01:53:23.335 --> 01:53:28.195
Um, so, uh, we'll use softmax in later labs as well.

1777
01:53:28.735 --> 01:53:33.235
Um, so, um, since we are not using the probabilities

1778
01:53:33.815 --> 01:53:35.595
in any fashion directly, uh,

1779
01:53:35.655 --> 01:53:39.075
and we can just use the Logic Max, all those logics for,

1780
01:53:39.785 --> 01:53:41.565
for predicting what the digit is,

1781
01:53:41.945 --> 01:53:44.725
but softmax, using softmax is the cleaner way,

1782
01:53:45.145 --> 01:53:46.285
uh, right way to do it.

1783
01:53:46.865 --> 01:53:47.605
Uh, yeah.

1784
01:53:53.705 --> 01:53:55.805
It wasn't used to just make a point here.

1785
01:53:56.025 --> 01:53:59.785
Uh, there's no particular reason. Uh, cool.

1786
01:54:00.365 --> 01:54:01.265
So, um,

1787
01:54:06.415 --> 01:54:06.925
let's see.

1788
01:54:06.985 --> 01:54:09.085
Uh, do you guys have this class for two hours

1789
01:54:09.185 --> 01:54:10.205
or four hours today?

1790
01:54:10.315 --> 01:54:11.085
Just want to check.

1791
01:54:17.895 --> 01:54:21.305
Okay. Okay. I know we're, we're a bit over time.

1792
01:54:21.485 --> 01:54:25.025
Uh, I want to quick take a quick poll from the class.

1793
01:54:25.325 --> 01:54:28.145
Uh, do you guys want to go through, uh, like, you know,

1794
01:54:28.285 --> 01:54:29.745
few slides on cnn,

1795
01:54:30.205 --> 01:54:32.945
or do you want to, you know, just pick it up tomorrow?

1796
01:54:32.945 --> 01:54:36.465
Either is fine. I just want to take a quick poll.

1797
01:54:36.645 --> 01:54:40.345
Uh, okay.

1798
01:54:40.415 --> 01:54:42.865
Even if one says tomorrow, we'll start tomorrow, uh,

1799
01:54:42.865 --> 01:54:44.985
because, you know, I wanna make sure everyone is

1800
01:54:44.985 --> 01:54:46.345
comfortable with that schedule.

1801
01:54:47.005 --> 01:54:50.425
So, so tomorrow, uh, let's quickly review the

1802
01:54:51.785 --> 01:54:54.645
agenda for tomorrow, and we'll wrap this class up today.

1803
01:54:55.345 --> 01:54:58.585
Uh, and, uh, yeah,

1804
01:54:58.645 --> 01:55:00.905
and we'll meet back tomorrow to discuss.

1805
01:55:02.515 --> 01:55:05.255
So, uh, let's quickly dis, uh, discuss like, you know,

1806
01:55:05.255 --> 01:55:06.375
advantages of F and n.

1807
01:55:06.475 --> 01:55:10.255
Um, so, um, again, lot of deep learning

1808
01:55:10.825 --> 01:55:14.375
advantages, uh, are applicable here.

1809
01:55:14.605 --> 01:55:17.175
Like, you know, end-to-end learning, um,

1810
01:55:19.755 --> 01:55:22.895
um, transfer learning, uh, scalability

1811
01:55:22.955 --> 01:55:27.055
and parallelization, um, um, uh,

1812
01:55:27.055 --> 01:55:28.935
universal approximators, uh,

1813
01:55:29.075 --> 01:55:32.095
and a lot of nonlinear modeling, like, you know,

1814
01:55:32.095 --> 01:55:35.215
using multimodal data and, uh,

1815
01:55:35.675 --> 01:55:37.215
and as such, um,

1816
01:55:38.975 --> 01:55:43.565
and, um, some of the challenges, uh, again,

1817
01:55:43.565 --> 01:55:47.205
these are, uh, uh, addressed with the pictures

1818
01:55:47.205 --> 01:55:51.245
that we'll look at in the, uh, next sections is, you know,

1819
01:55:51.695 --> 01:55:54.565
there is no sequentiality in the, in the small, right?

1820
01:55:54.745 --> 01:55:59.085
So, um, um, for example, you know,

1821
01:55:59.585 --> 01:56:02.285
by inherent nature, they like the ability

1822
01:56:02.385 --> 01:56:03.685
to model sequential.

1823
01:56:03.685 --> 01:56:05.965
There is no temporal component, like, uh,

1824
01:56:06.105 --> 01:56:07.805
the data is flowing in one direction,

1825
01:56:07.805 --> 01:56:09.605
but there are no loops as such.

1826
01:56:10.345 --> 01:56:14.005
Um, so, so these are addressed through other types

1827
01:56:14.005 --> 01:56:16.645
of network architectures like, uh, recurrent, uh,

1828
01:56:16.715 --> 01:56:20.925
neur networks, uh, and there variance like l SDMs and G.

1829
01:56:22.985 --> 01:56:26.605
So for, for tasks involving sequential data, uh,

1830
01:56:26.665 --> 01:56:31.205
and are less, uh, fns are less, uh, applicable,

1831
01:56:31.465 --> 01:56:35.365
uh, and these are not, uh, um, very good at those.

1832
01:56:35.465 --> 01:56:40.245
So, so for those who use R ns, um, also like, um,

1833
01:56:41.385 --> 01:56:43.205
uh, inefficient parameter sharing.

1834
01:56:43.335 --> 01:56:44.605
Let's, let's talk about that.

1835
01:56:44.705 --> 01:56:49.465
So, so we'll talk about this concept in depth in CNNs,

1836
01:56:49.485 --> 01:56:52.905
but, um, essentially, uh, n

1837
01:56:52.905 --> 01:56:53.945
and Ns, uh,

1838
01:56:54.085 --> 01:56:56.625
are using all the data elements in a

1839
01:56:56.625 --> 01:56:57.905
densely connected manner.

1840
01:56:58.685 --> 01:57:02.815
Um, so, uh, as you're learning the,

1841
01:57:04.305 --> 01:57:08.605
the input, um, there is less parameter sharing, uh,

1842
01:57:08.715 --> 01:57:13.445
because, um, uh, the connected layers

1843
01:57:13.445 --> 01:57:16.885
where every neuron is connected to every neuron, uh,

1844
01:57:16.885 --> 01:57:20.525
every other neuron in the, in the next layer, uh, this leads

1845
01:57:20.585 --> 01:57:22.845
to like, you know, large number of parameters,

1846
01:57:22.845 --> 01:57:24.125
explosion of parameters.

1847
01:57:24.665 --> 01:57:26.245
Uh, so let's fake, for example,

1848
01:57:26.245 --> 01:57:30.525
like if you take like a one mega X cell image, um, so

1849
01:57:30.525 --> 01:57:33.365
that's like, uh, you know, um, um,

1850
01:57:34.805 --> 01:57:35.885
thousand times thousand, right?

1851
01:57:36.145 --> 01:57:39.525
Uh, pixels. Um, so, uh, so

1852
01:57:40.395 --> 01:57:44.365
even when you're starting, you, it have like an explosion

1853
01:57:44.545 --> 01:57:47.925
of, uh, parameters, uh, already a million.

1854
01:57:48.505 --> 01:57:51.125
And then as you go through the layers there, if you were,

1855
01:57:51.125 --> 01:57:53.445
if you're doing it in a densely connected fashion,

1856
01:57:53.875 --> 01:57:57.045
like let's say 1 million times, the next layer is probably,

1857
01:57:57.165 --> 01:57:58.205
I don't know, 0.5 million.

1858
01:57:58.545 --> 01:58:00.245
That's, that's a huge explosion.

1859
01:58:00.385 --> 01:58:05.365
Um, uh, yes, FNS are fully connected, uh, uh,

1860
01:58:05.705 --> 01:58:08.045
uh, networks, uh, all the time.

1861
01:58:08.265 --> 01:58:08.485
Yes.

1862
01:58:13.605 --> 01:58:18.035
Um, also, uh, s

1863
01:58:18.295 --> 01:58:21.075
by in, by their inherent nature, like, you know, um,

1864
01:58:21.785 --> 01:58:25.075
this comes back to the sequential aspect of it, um,

1865
01:58:25.295 --> 01:58:27.475
are not naturally equipped to handle inputs

1866
01:58:27.475 --> 01:58:30.435
of variable length and sizes like, like, you know,

1867
01:58:30.695 --> 01:58:31.915
for speech recognition

1868
01:58:32.055 --> 01:58:34.555
or input sequences that have variable length.

1869
01:58:35.375 --> 01:58:38.595
Um, uh, it's, it's not, uh, uh,

1870
01:58:38.745 --> 01:58:40.355
they can't handle that efficiently.

1871
01:58:40.535 --> 01:58:42.445
You need to handle it outside of the network.

1872
01:58:43.185 --> 01:58:46.765
Uh, s uh, come to rescue in those particular cases.

1873
01:58:48.265 --> 01:58:52.045
Um, there is also like, you know, lack of state

1874
01:58:52.225 --> 01:58:56.445
or lack of memory in the network itself, uh, like, you know,

1875
01:58:56.915 --> 01:58:58.485
capturing previous state

1876
01:58:58.665 --> 01:59:03.485
and using that information to, uh, as a context to,

1877
01:59:03.905 --> 01:59:05.205
to, uh, learn better.

1878
01:59:05.785 --> 01:59:08.765
Um, so again, that sort of capital doesn't exist

1879
01:59:08.825 --> 01:59:11.885
and is more addressed directly in LSTs

1880
01:59:11.885 --> 01:59:15.525
and gs, uh, uh, architectures.

1881
01:59:18.035 --> 01:59:22.465
Yeah. So parameter sharing will look at in depth, uh,

1882
01:59:22.725 --> 01:59:25.385
for CNN's, uh, Regina, what I meant by that.

1883
01:59:25.605 --> 01:59:29.945
Uh, so, uh, it's, it's a, it's a much deeper concept,

1884
01:59:30.035 --> 01:59:32.705
which I, I think it'll take some more time, uh,

1885
01:59:32.845 --> 01:59:34.945
and we'll look at it in depth in the cnn.

1886
01:59:34.945 --> 01:59:39.105
So, uh, let's part that to the next session, uh,

1887
01:59:39.485 --> 01:59:41.105
and we'll, we'll talk about that.

1888
01:59:41.765 --> 01:59:44.105
Um, so, so, uh, let's keep moving.

1889
01:59:44.845 --> 01:59:48.705
Interpretability, uh, again, this is in general a challenge

1890
01:59:49.165 --> 01:59:51.385
of, uh, deep neural networks.

1891
01:59:51.525 --> 01:59:53.705
Uh, so, uh, nothing new here.

1892
01:59:53.885 --> 01:59:57.225
So, FNS, uh, they operate as black box models.

1893
01:59:57.925 --> 02:00:01.385
Um, uh, that makes it difficult to understand

1894
02:00:01.385 --> 02:00:03.465
how the network arrives at a given

1895
02:00:03.465 --> 02:00:05.265
conclusion or a prediction.

1896
02:00:06.405 --> 02:00:11.345
Uh, as I said, if you want interpretability of opt for, uh,

1897
02:00:11.985 --> 02:00:15.185
addition trees or more linear models, uh,

1898
02:00:15.455 --> 02:00:18.625
that are typically more transparent and interpretable.

1899
02:00:25.465 --> 02:00:29.775
Um, yeah, some, some applications, uh, of f

1900
02:00:29.775 --> 02:00:33.575
and Ns, like, um, widely used in, uh,

1901
02:00:33.575 --> 02:00:36.255
pattern recognition tasks, uh, such

1902
02:00:36.255 --> 02:00:38.695
as like character recognition, which we just saw,

1903
02:00:39.495 --> 02:00:42.775
a handwriting, recognition, object recognition and images.

1904
02:00:43.515 --> 02:00:46.935
Uh, they can learn to identify, uh, you know, making, um,

1905
02:00:47.635 --> 02:00:51.255
and classify patterns in data that makes it, uh,

1906
02:00:51.655 --> 02:00:53.555
valuable in those use cases.

1907
02:00:54.335 --> 02:00:59.275
Uh, used a lot in, uh, fraud detection, uh, like,

1908
02:00:59.275 --> 02:01:02.795
you know, credit card transactions, insurance claims, uh,

1909
02:01:02.895 --> 02:01:06.155
by learning patterns in historical data, uh, f

1910
02:01:06.155 --> 02:01:08.915
and Ns can identify anomalies, um,

1911
02:01:09.215 --> 02:01:13.995
and flag potentially, uh, fraudulent transactions, uh,

1912
02:01:14.575 --> 02:01:18.155
for, uh, you know, they're used in, you know,

1913
02:01:18.545 --> 02:01:22.195
like things like, you know, customer churn, product churn,

1914
02:01:22.195 --> 02:01:24.555
prediction, like, you know, customer attrition prediction.

1915
02:01:24.975 --> 02:01:27.995
Uh, those are some use cases. F and Ns are typically used.

1916
02:01:29.315 --> 02:01:34.175
Um, they can be used for sentiment analysis, uh, given a

1917
02:01:35.215 --> 02:01:36.295
corpus of text

1918
02:01:36.555 --> 02:01:39.565
and their embeddings, you can classify that as, you know,

1919
02:01:39.965 --> 02:01:41.125
positive or negative sentiment.

1920
02:01:41.745 --> 02:01:46.245
Um, s are used in financial forecasting, uh, like, you know,

1921
02:01:46.245 --> 02:01:47.445
stock market prediction

1922
02:01:47.745 --> 02:01:51.285
or economic prediction, stuff like that.

1923
02:01:52.395 --> 02:01:54.855
Um, so, and recommendations.

1924
02:01:54.855 --> 02:01:57.175
They're used like, you know, s uh,

1925
02:01:57.175 --> 02:01:59.415
play a big role in collaborative filtering

1926
02:01:59.415 --> 02:02:01.015
and content based filtering methods.

1927
02:02:01.955 --> 02:02:05.695
Um, so, so those are some real world applications where

1928
02:02:06.215 --> 02:02:10.935
s are heavily used, um, uh, in practice.

1929
02:02:21.475 --> 02:02:25.725
Alright, so, yeah,

1930
02:02:25.885 --> 02:02:28.605
I don't know why the font is kind of showing it this way.

1931
02:02:28.745 --> 02:02:33.405
So, so we talked, uh, uh, uh, maybe lemme go back to this.

1932
02:02:45.105 --> 02:02:48.595
Yeah. So we talked about, you know, uh, f

1933
02:02:48.595 --> 02:02:53.235
and Ns, um, how the, the, the basic structure

1934
02:02:53.235 --> 02:02:56.475
of f is like, you know, the fully connected nature of them,

1935
02:02:57.295 --> 02:02:59.915
uh, discussion of input layer, output layer,

1936
02:02:59.935 --> 02:03:01.915
and hidden layers, um,

1937
02:03:02.335 --> 02:03:06.185
and, uh, you know, limitations of f

1938
02:03:06.185 --> 02:03:08.265
and n like, you know, uh, the recurrent nature

1939
02:03:08.685 --> 02:03:10.025
or parameter sharing,

1940
02:03:10.025 --> 02:03:13.385
which we'll talk in depth in the next class, um,

1941
02:03:14.005 --> 02:03:18.385
or, uh, uh, inability to maintain state

1942
02:03:18.485 --> 02:03:19.505
or some sort of memory.

1943
02:03:21.185 --> 02:03:24.245
And we also looked at a working example, like, you know, how

1944
02:03:24.305 --> 02:03:27.325
to classify handwritten digits using F and n.

1945
02:03:27.785 --> 02:03:30.765
Uh, so that's a quick summary of, uh, today's f and n class.

1946
02:03:31.585 --> 02:03:36.485
Um, so we'll stop the instruction here

1947
02:03:36.945 --> 02:03:38.805
and I'll stay around for like five minutes

1948
02:03:38.985 --> 02:03:40.405
to answer any questions.

1949
02:03:41.065 --> 02:03:45.325
Um, and we'll pick it up in the next class with CNNs

1950
02:03:45.905 --> 02:03:48.965
and s um, and we'll wrap this up.

1951
02:03:49.465 --> 02:03:52.165
So, uh, in the CNNs we'll look at like, you know,

1952
02:03:52.195 --> 02:03:55.325
what are the salient features of those networks, uh,

1953
02:03:55.545 --> 02:03:58.845
and you know, how the parameters are effectively shared

1954
02:03:58.845 --> 02:04:01.885
there and all of that, uh, and,

1955
02:04:02.345 --> 02:04:06.445
and s uh, as well, like, you know, why, uh,

1956
02:04:06.945 --> 02:04:08.165
RNs are important

1957
02:04:08.745 --> 02:04:11.565
and, uh, what kind of problems they're suitable to solve

1958
02:04:11.565 --> 02:04:13.365
with, um, and all of that.

1959
02:04:13.465 --> 02:04:15.565
So, so that's for next class.

1960
02:04:15.785 --> 02:04:17.325
Uh, we'll discuss in depth there.

1961
02:04:17.985 --> 02:04:22.575
But, um, let's, uh, uh, pause there,

1962
02:04:23.315 --> 02:04:25.695
uh, for today and I'll hang around

1963
02:04:25.695 --> 02:04:27.415
for a little bit if you have questions.

1964
02:04:32.955 --> 02:04:34.565
Alright, thanks everyone.

1965
02:04:34.705 --> 02:04:38.525
Um, um, again, um, just, uh, uh,

1966
02:04:38.705 --> 02:04:41.085
review the material if you can today,

1967
02:04:41.085 --> 02:04:42.845
but it shouldn't be a blocker for tomorrow.

1968
02:04:43.425 --> 02:04:46.925
Uh, we'll look at, you know, how CNN architectures

1969
02:04:47.025 --> 02:04:51.325
and RNN architectures contrast to how operate

1970
02:04:52.025 --> 02:04:54.665
and what is the motivation behind those architectures.

1971
02:04:54.685 --> 02:04:58.585
So we'll have a nice, uh, learning around that tomorrow.

1972
02:04:58.765 --> 02:05:00.985
So, uh, look forward to meeting you all tomorrow.

1973
02:05:01.365 --> 02:05:04.985
Um, um, so have a good, uh, rest of the day. Thank you.
